{"pages":[{"title":"About","text":"关于不出教程，日常记录，如果有帮到你那再好不过了 如果对你有大帮助，请我喝肥宅快乐水？ 一点积累，瞎鸡儿折腾，恐怕剩不下太多东西 一切安好 Whoami 调律者/Zz.Mark HuFi/业余音控 PA/业余灯光 佛系 Gamer Java/北京 业余爱好丰富 反猫狗体质 SNS Email: zz.mark06###gmail.com github: https://github.com/ZzMark Twitter: Zz_Mark06 Steam: zz_mark PSN: Zz_Luka Echo本博客采用 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 进行许可内容均为原创或网上整理，如果侵犯了您的权利，请邮件联系我。如果您要抄走，希望著名Powered by Hexo.Theme by hexo-theme-icarus.Made some changes.","link":"/about/index.html"}],"posts":[{"title":"i18n-Accept-Language相关研究","text":"网页端 i18n 必然会涉及到的 header 就是 Accept-Language 相关内容可以直接参考 MDN Accept-Language 不过这个字段对于中文，有许多历史遗留问题，这里只讲最终结论 关于 Accept-Language 以及各种操作系统 lang 的取值，遵守的标准是 ieft-BCP47 Tags for Identifying Languages zh, zh-CN, zh-Hans, zh-Hant 之间的关系如果你的系统语言环境是 简体中文，那么 chrome 浏览器会默认将 Accept-Language 填写为 zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-HK;q=0.6 这其中有很多有趣的点可以解读 首先，zh-CH,zh;q=0.9，这其实是两部分，写完整的话应该是 zh-CH;q=1.0,zh;q=0.9 用q做了一个优先度 但这俩都是中文，目前大多数的服务端，都会将 zh-CN 当作 简体中文，但实际上并不正确，这就是历史遗留问题第二种 zh 实际上也是废弃标准，但绝大多数服务端，都没有舍弃这两种废弃标准的使用。 类似的还有很多，如 12zh-Hans, zh-Hans-CN, zh-cmn, zh-cmn-Hans, zh-wuu, zh-yue, zh-ganzh-Hans-HK、zh-Hans-MO、zh-Hans-TW、zh-Hant 严格上来说，语言的标记格式为 12language -extlang -script -region -variant -extension -privateuse语言文字种类 -扩展语言文字种类 -书写格式 -国家和地区 -变体 -扩展 -私有 123zh 中文，因为无法指代语言，所以废弃。但大部分服务端将此认定为 zh-Hanszh-Hans 汉语-简体(han 汉语, s Simplified_Chinese)zh-Hant 汉语-繁体(t Traditional_Chinese) 实际上还有一些极为不常用的中文语种 1zh-cmm 还有同样不常用，而且不符合标准，但还是有用到的 123zh-SGzh-TWzh-HK 还有些符合标准，但并不在 Accept-Language 中受到支持的完整写法(我是不知道啥服务器认这个) 1234zh-cmn-Hans 国语-简体中文zh-cmn-Hant 国语-繁体中文zh-yue-Hant 粤语-繁体中文zh-wuu-Hans 上海话-简体中文 其中 cmn 是国语，yue 是粤语，wuu 是上海话 后端如何做适配长远打算，最好兼容 BCP47，不过现阶段有很多历史遗留用法反而是主流 目前来说，做好这些兼容就是 1zh, zh-CN, zh-Hans, zh-cmn-Hans, Hans 都解析成中文 不过这是一己之见，没有什么依据 短期来看，支持个 zh, zh-CN, zh-Hans 其实就够了 springboot我们的后端使用这个，所以特意说一手 默认情况下，springboot 会将 Accept-Language: zh-CN 解析成 Accept-Language: zh-Hans 匹配 message_zh_Hans.properties 若不存在，降级到 zh_CN 观测结果 简单追查，可以得出 zh-Hans 继承于 zh-CN 不过这个机制，并不是 springboot 或者 spring 的机制，是jre机制 java.util.ResourceBundle.Control#getCandidateLocales 方法的注释中，有写明对于 Chinese 的特殊处理在线版本可以参考 https://docs.oracle.com/javase/8/docs/api/java/util/ResourceBundle.Control.html 123456789101112131415161718Special cases for Chinese. When an input Locale has the language &quot;zh&quot; (Chinese)and an empty script value, either &quot;Hans&quot; (Simplified) or &quot;Hant&quot; (Traditional)might be supplied, depending on the country. When the country is &quot;CN&quot; (China)or &quot;SG&quot; (Singapore), &quot;Hans&quot; is supplied. When the country is &quot;HK&quot; (Hong KongSAR China), &quot;MO&quot; (Macau SAR China), or &quot;TW&quot; (Taiwan), &quot;Hant&quot; is supplied. For all other countries or when the country is empty, no script is supplied.For example, for Locale(&quot;zh&quot;, &quot;CN&quot;) , the candidate list will be: [L(&quot;zh&quot;), S(&quot;Hans&quot;), C(&quot;CN&quot;)] [L(&quot;zh&quot;), S(&quot;Hans&quot;)] [L(&quot;zh&quot;), C(&quot;CN&quot;)] [L(&quot;zh&quot;)] Locale.ROOTFor Locale(&quot;zh&quot;, &quot;TW&quot;), the candidate list will be: [L(&quot;zh&quot;), S(&quot;Hant&quot;), C(&quot;TW&quot;)] [L(&quot;zh&quot;), S(&quot;Hant&quot;)] [L(&quot;zh&quot;), C(&quot;TW&quot;)] [L(&quot;zh&quot;)] Locale.ROOT 过于前沿，还没啥用的知识BCP47 在 2009年，将 zh 废弃，把 Hans, Hant 提升到了 language 层级也就是说，zh-Hans 应写成 Hans 不过这个设定，没有程序认……","link":"/2020/09/id_2756259807/"},{"title":"Thinkpad E440 升级记录","text":"陪伴了我6年的笔记本，折腾了这么久，整理一下笔记 before这笔记本，也算是被我拉到一定高度了，能升级的各种升级，能拉到顶的基本都往顶上拉 联想的老本子(16年前的型号)大多数都有 pcie 白名单，也就是没法随心所欲换无线网卡 原本配置： 1234567CPU: i5 4200m(双核四线程 2.5GHz/3.1G TDP 37W)显卡: Nvidia Geforce GT840M 总之够弱内存: 4G ddr3 1600硬盘: WD 500g 5400rpm 7mm 薄盘屏幕: 1366 x 768 京东方辣眼屏幕(不是诋毁京东方，只是这块屏太低端了)有线网卡: RTL8111 后边啥忘了，普通的千兆卡无线网卡: RTL8723BE, wifi单2.4g 300m，蓝牙4.0，双天线，mpcie update升级过后 1234567CPU: i7 4710mq(四核八线程 2.5GHz/3.5G TDP 47W)显卡: Nvidia Geforce GT840M 显卡我也换不了内存: 8G ddr3 1600 x2，拉满16g内存硬盘: 镁光 m550 240g, 老机器剩下的屏幕: 友达 b140han01.7 1920 x 1080 ips 就是薄了点，孔位不对，上了胶水有线网卡: RTL8111 后边啥忘了，普通的千兆卡无线网卡: intel 7260ac, wifi 双频 300/867，蓝牙4.0，双天线，mpcie，不支持mu-mimo，除了魔改安装白果原装卡之外最高的型号了 屏幕屏幕升级是16年的事，只记得原装屏幕和这个差了0.5mm厚度，所以屏幕有缝隙；下边孔位对不上，最后拿胶水粘上的。总之最终效果很好 笔记本换屏幕，确保接口一致，电压一致，就ok。当然记得注意接口带宽够不够。比如朋友的 dell 灵越7537 768p的就没法直接换1080p，需要补主板上的零件 附上辣鸡原装屏淘宝的价格(16年换屏幕时候，原装屏80块就能收到) cpu这一代笔记本可以换cpu，有几个可选的目标， qdet，不显ES，应该只有一两百块，有赌的成分，性能基本等同于 4700mq i7 4700mq/4710mq，两者区别不大，价格也是 i7 4800mq，太热，必须关掉超线程才能快乐玩耍 i7 4770hq PGA转接，性能比4800mq强一丢丢，核显是 irs 5200，虽然没啥大用。现在不好买到了 当然，4700mq，性能也就只有 amd ryzen r5 4600u 的一半。感慨时代变迁啊(不过人家6c12t，咱4c8t，差这么多年，输了不丢人) 先纠正一个点，TDP不是功耗 intel 的解释 英特尔®处理器中的散热设计功耗（TDP）。 TDP能否看作CPU与GPU的额定功率? - 黎小白的回答 - 知乎 无线网卡白名单内只支持三个卡e440 20c5 一共支持三块无线网卡，分别是 rtl8723be intel n-7260(单频版本) intel 7260ac(官方文档说支持，但bios里的硬件id还是单频的版本，不晓得官方说的是哪个型号) 以下内容均基于修改白名单。 可选项其实没几个，因为 minipcie 实在是没啥新卡了 不外乎两个思路，转接/不转接 e440 无线网卡仓位，是标准的半高 mini-pcie 27mm x 30mm ，单侧螺丝柱，垂直方面还是有不少余地，可以大胆上转接卡，不会被厚度限制 长度其实也很足够，能塞下全高 mini-pcie 27mm x 51mm 的仓位，若是转接卡没有留半高的螺丝孔位，也可以自己拿胶水粘上，不会出问题(当然，胶水要靠谱才行) 转接的话，必然是 mini-pcie to ngff(m.2)，可选卡就挺多了。几个个人推荐 intel ax210 100块 (最新卡，特性很全，支持wifi6e，蓝牙5.2，需要重新拉天线，自带天线没法跑6G) intel ax200 60块 (intel 比 ax210 旧一代的卡，wifi6，蓝牙5.1，也算是笔记本能用最好程度) 博通 BCM943602BAED，戴尔的 DW1830，天价，没啥意思 m2 无线网卡一般的尺寸都是 2230，用转接卡肯定要长于原本的长度，若是转接卡没有留螺丝孔，那就 还有白果原装卡，需要特制的转接卡(毕竟接口不同)，驱动找 bootcamp 中提取，就像是白果装 win 那样 bcm943602CS 大概要200块。15年的卡，450/1300，蓝牙4.1，(我刚知道这卡的时候，60块就能拿到……) bcm94360cd，最高规格(大概)的卡，13年的老卡，四天线卡(3t3r，蓝牙单独一根)，蓝牙4.0，不推荐使用 (450/1300)，容易遇到魔改版本 2.4g 600m的怪胎 bcm94360cs2，这是老卡，不推荐，也不便宜 BCM94360CSAX，也是老卡，不推荐，也贵得要死 若是非转接，那就只有两种选择了 intel 7260ac，50块 wifi 双频 300/867，蓝牙4.0，双天线，不支持mu-mimo 博通 bcm94352z，贵 博通 bcm94360hmb 三天线卡，贵得很 高通的卡，我不了解 我对苹果的无线算是很了解，但出于成本和复杂度，我最终选择了 7260ac，毕竟折腾 ax200 也没啥意思，转接卡也要三四十块 TODO 我还考虑要改散热，现在的u还是太热了，或许我也可以考虑关掉超线程。 也在考虑是否能加上个 wwan 卡，目前还在调查中 电池其实也不太行了，损耗达到了50%，不过用的也很少，可能短期内不考虑这个了","link":"/2021/01/id_3598269465/"},{"title":"TIME_WAIT 过高排查记录","text":"线上服务器遇到了 TIME_WAIT 很高的情况，虽然服务没什么问题，机器剩余的配置很大(总计占用还不足机器的五分之一)，不过这问题很可能成为隐患，所以排查了一番，记录如下： 基础知识 TIME_WAIT 的来源 TCP 的三次握手、四次挥手，常用的三个状态是：ESTABLISHED 表示正在通信，TIME_WAIT 表示主动关闭，CLOSE_WAIT 表示被动关闭三次握手：第一次，主动端发送SYN给 LISTEN 中的被动端，自己切换至 SYN-SENT 状态；第二次，被动端发送ACK确认收到信号和SYN；第三次，主动端发送ACK确认收到被动端SYN。完成上述动作后，两端进入enblished 四次挥手中，第一次是主动端断开，发送FIN信号，切换至FIN-WAIT-1状态；第二次是被动端收到FIN信号，切换至CLOSE-WAIT状态，然后发送ACK至主动端，主动端收到后切换至FIN-WAIT-2；第三次是被动端等自己的应用断开连接时，发送FIN信号给主动端，被动端切换至LAST-ACK；第四次是主动端收到被动端的FIN信号，然后发送ACK信号，切换至TIME-WAIT状态，等待内核回收。 百度带来的坑随手搜索问题之后，无论是 baidu 还是 google，搜到的大量内容，都是叫你优化 net.ipv4 这种治标不治本的方法，什么加快 TIME_WAIT 回收啊，增大量级啊 但是，问题的来源并没有解决，以往的经验表明，这么调整或许能解决问题，但连接反复开闭产生的资源消耗依然很大 定位 TIME_WAIT 原因根据 TCP 握手规则，谁有TIME-WAIT，谁就是主动端。这点可以排除用户频繁访问或错误的释放连接的可能。 意思就是说这都是服务器主动请求断开连接的，而TIME-WAIT状态的链接也没有回收。 服务端可能产生的请求，也就只有服务间互相调用、访问第三方 API、反向代理 其实到这里已经快要破案了，要么是程序的 bug，要么是反向代理配置带来的大量 TIME_WAIT 接下来就是具体定位，连接到底是谁产生的了。 拓扑目前线上很精简，只有一台机器，使用 docker 作为业务容器，外侧 nginx 做入口 1234 (docker) |-----------------|nginx -&gt; traefik -&gt; api |-----------------| nginx 持有 80 443 端口，traefik 通过 12500 暴露到主机，docker内的服务不对主机暴露端口 为啥这么设计？ Let’s encrypt 的证书最近因 akamai 被墙导致 OCSP 无法执行，iOS 端首次请求会等待数秒钟，这对于用户不可接受，而我们又没有购买证书或者更换国内证书的打算(子域名有点多，申请起来太累，还是 acme.sh 来得爽)(还是穷的) 然而 traefik 并不能处理 OCSP stapling，只好让 nginx 扛起 https 的大任 命令排查(因为执行时的命令结果没有保存，所以这里只有看出情况的命令行了) 查看 TIME_WAIT 属于哪个连接 1netstat -tn|grep TIME_WAIT|awk '{print $4}'|sort|uniq -c|sort -nr|head 123[root@m ~]# netstat -tn|grep TIME_WAIT|awk '{print $4}'|sort|uniq -c|sort -nr|head 2703 127.0.0.1:12500 2 172.17.3.142:3306 可以看出，127.0.0.1:12500 持有 2703个 TIME_WAIT，这个端口是后端API服务的监听端口。因为 TIME_WAIT 都是主动方持有，也就是说请求是由本机的程序发往后端 API 的，也就是猜测中的第三种-反向代理的请求 不过这还没法破案，然后是分析请求来源 1netstat -ant|grep 127.0.0.1:12500 12345678910111213141516171819[root@m ~]# netstat -antp|grep 127.0.0.1:12500tcp 0 0 127.0.0.1:37860 127.0.0.1:12500 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37828 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37748 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37782 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37728 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37802 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37864 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37720 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37770 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37844 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37810 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37852 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37752 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37742 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37870 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37832 TIME_WAIT -tcp6 0 0 127.0.0.1:12500 127.0.0.1:37762 TIME_WAIT -... 因为都在本地，这命令下去根本看不出啥来如果是外来请求，或者其他 ip 的请求，那么后方的 127.0.0.1 就会显示那一方的 ip 如果运气好，能看到 127.0.0.1:12500 在后边，也就是第五个参数位置，那么可以尝试翻一翻是否有最后一个参数，若 TIME_WAIT 占比不是特别绝望，应该能看到几个。而这几个很有可能就是发起者。也算是种猜测了。 到这里我也没什么排查手段了，因为请求来源是 127.0.0.1，不好确认是哪里来的请求。这也就是单节点带来的痛苦…… 不过按照前面的线索，nginx 的可能性很大 nginx 带来的 TIME_WAIT 导致 nginx端出现大量TIME_WAIT的情况有两种： keepalive_requests设置比较小，高并发下超过此值后nginx会强制关闭和客户端保持的keepalive长连接；（主动关闭连接后导致nginx出现TIME_WAIT）keepalive设置的比较小（空闲数太小），导致高并发下nginx会频繁出现连接数震荡（超过该值会关闭连接），不停的关闭、开启和后端server保持的keepalive长连接； 解决方案 对于反向代理，nginx 提供了一个 upstream 的参数： 1234upstream http_backend { server 127.0.0.1:12500; keepalive 50;} 这样便能解决问题。 下面是该参数的相关逻辑以及官方对此的说明： http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive The connections parameter sets the maximum number of idle keepalive connections to upstream servers that are preserved in the cache of each worker process. When this number is exceeded, the least recently used connections are closed.（设置每个 worker 进程保留与上游服务器的 keepalive 连接最大数量。超过此数量时，将关闭最近最少使用的连接。） It should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open.（特别提醒：keepalive指令不会限制一个nginx worker到 upstream 连接的总数量）","link":"/2020/07/id_708295649/"},{"title":"Thinkpad E440 白名单","text":"本文就是与白名单斗争的血泪史 白名单一共有两种对抗手段 修改逻辑，废除白名单校验功能，直白的讲，就是有个判断，不让代码执行就ok了 修改数据库，让自己要换的卡成为bios支持的卡。原本支持三块无线网卡，把其中一个的id替换成新卡的id就行 我最终使用了第二种 修改数据库 的方案，就是替换已有的硬件id 目前，网上修改白名单的教程，都太老啦，现在工具链比以前先进了很多(感谢vit9696大神的LongSoft/UEFITool) 所以我这里用了新的手段，更简单了 读取bios 用 UEFITool 找到目标模块，配合 二进制编辑器(我用的 HxD) 替换某块已存在的网卡 烧录回去 但是，因为intel的安全限制，更新bios是有校验的，笔记本无法随便刷 bios，也就是你改完了bios，却没法用原本的软件刷入 所以，想要修改 bios，需要直接用编程器去烧录 bios 芯片 以下就是翻车全过程 e440 的 bios 分为两个芯片存放，64MBit的 Bios，32MBit的 EC 我有编程器，但是个山寨货，满淘宝都是同款山寨，毕竟就只是个SPI串口烧录，没有核心技术。开源的板都抄不明白必须得告别这个行业了。 山寨烧录器配的烧录软件，也是破解版本，最大的坑点，也是翻大车的理由 官网的 bios 文件，是 12Mbyte(注意单位，1Mbyte = 8MBit)，我没有分离手段，也就是我只能靠备份来拿原始 bios 我不太想拆 bios，考虑过 SOP 夹子，但这东西，用过的都知道，十几块的玩意就跟一次性一样，而这个笔记本有俩芯片， 所以我最终选择了这个东西 但是买的时候，忘记考虑尺寸，到手发现，根本夹不上去，最后还是上烙铁焊下来 读取 买编程器的时候，都会有配套的软件，鉴于很多人购买的 CH341A 编程器是山寨产品、软件均是破解来的盗版（正版：skygz.taobao.com） 破解来的软件非常不好用（芯片支持不够、报错闪退等） 所以，强烈建议大家丢弃那个破软件 满网都是盗版，各种投毒，支持芯片少之又少。 推荐使用 AsProgrammer，有 dalao的汉化，还有简单的说明：介绍一款 CH341A 编程/烧录 软件 AsProgrammer 汉化版 读取的过程，没啥的。 我的主板，bios和ec是分成两个芯片的，型号分别为 winbond 25q64fvsig 和 winbond 25q32fvsig，之前已经提到，32MBit的是EC，64MBit的是bios(我怎么知道的？没什么神奇的，翻资料) thinkpad 的白名单功能，在EC中，所以需要读取的是 32MBit 的那个。 软件那边，能识别出芯片，就是没问题，具体的芯片型号可以直接看芯片的丝印 若识别错误，可能是接触不良，去排查线路。 读取过程，一定要多读取几次，不要怕耽误时间。 多次读取后，把每一次的都丢进 文件 crc32 算一下是否一致 这个可以随便找在线工具，比如这个 文件校验 最好是读取三次，都一致就ok，若有不一致的，再读几次，确保大部分都是一致的，那个版本基本不会是损坏的 修改网上各种教程会让你使用 PhoenixTool 解包，用xsearch搜索，再修改，然后用工具打包。这一堆操作很容易出问题，所以我用更加便捷的工具来做这个。感谢vit9696 所需工具，一共两个， LongSoft/UEFITool HxD 或者 winhex 下载 UEFITool 时，注意版本，带NE的版本只有查看和提取能力，不能替换。我们需要不带NE的完全版本，替换模块 首先掌握一个基本技能，就是转换硬件id 1234567891011// 参考网卡，rtl8723be 到设备管理器中寻找。没有留图PCI\\VEN_10EC&amp;DEV_B723&amp;SUBSYS_B72817AA&amp;REV_00// 提取每一部分，然后丢弃 REV (似乎这个不能丢弃，硬件id中有 REV01可能需要保留，但大部分都没有，起码我这个没有)10EC B723 B72817AA 00// 反写EC10 23B7 AA1728B7// 去掉空格，这就是最终结果，ec中存放的数据都是这个EC1023B7AA1728B7 定位要提取的模块白名单中肯定包含当前的卡搜索 Hex Pattern: header and body: EC1023B7AA1728B7当然，搜索 Text : Unauthorized network card is plugged 记得区分大小写，这句话来源于触发白名单时，屏幕上的提示 提取模块双击搜索结果，就能定位到我们要找的地方。右键 Extract body 提取出这个部分即可如果点击下面那一行的 User interface，可以在右侧看到 Text: LenovoWmaPolicyDxe，就是这个模块的名字 修改白名单这里采用了替换法，找一个替死鬼换掉即可 用二进制编辑工具，打开提取出的模块 搜索 EC1023B7AA1728B7，能看到三个网卡的硬件id 选择其中一个做替死鬼，将新网卡的id写入即可 保存，然后使用 UEFITool 替换刚刚提取的那个模块 右键-Replace Body 然后保存，保存的结果就是修改好的 EC 烧录回去将修改好的EC，刷回去，就行了 翻车记录我翻车的理由，要怪那个山寨的破解软件，不支持我的芯片，我还没有注意到 结果我修改了一个损坏的 EC，刷回去时也是损坏的。 最终，只能淘宝买一份原始 Bios，重新修改，两个都拆下来，两个都刷到原始版本，最终解决了问题 痛恨这傻逼的软件 另一种尝试其实，我还做了另一种尝试，虽然只走到了一半。 这个尝试极其复杂，外行止步 首先，额外需要的软件有 IDA Pro 用于反汇编，若要更好的分析流程，最好找个破解版，带 decompiler 反编译器的 其次，需要一个常识 这种涉及到偏移量的汇编，不要妄图增加一个赋值操作，或者删除某些代码，那需要重编译，否则容易导致破坏原有的执行，反而出现bug 思路就是，找到关键代码，桥接掉 顺着 Unauthorized network card is plugged 开始查找，可以找到以下函数 sub_690 这段代码决定了打印错误内容 通过 IDA 找到哪里调用了这个函数 图中的 while(1) ;，就是祸首 找到对应的汇编 然后，就是如何跳转到正确的位置 需要修改的时 123loc_826:...call sub_690 // 从这里开始，让代码跳转到下边的 loc_845 可惜，我专业能力不足，不晓得怎么跳转…… 毕竟我一点汇编都没学过…… 附录资源下载 介绍一款 CH341A 编程/烧录 软件 AsProgrammer 汉化版 LongSoft/UEFITool Hxd e440 (型号: 20c5 ver: 2.22 board: nw-151a) 工厂 Bios 其余的稍后补充","link":"/2021/01/id_3075796319/"},{"title":"acme.sh配置记录","text":"实际上这是个很简单又完善的工具，不过官网手册我看了好半天才理解，绕了很大的弯子 本文基于 CentOS 7 1708, nginx 1.12.2，acme.sh v2.8.0，环境和我的不相符也无所谓，但请不要完全照抄 文中的域名，均替换为了 example.com，伸手党注意鉴别。 本博目前使用的是 caddy，并没有用这个脚本，这是公司测试环境使用的东西 infoACME 协议: Automated Certificate Management Environment(自动证书管理环境)acme.sh: 一个自动管理证书的工具，可以用来自动申请和续期 Let’s Encrypt 证书 install首先安装工具，一行命令就能搞定，如果想要采用 standalone 模式（也就是不需要现有的web服务器，有80端口就可以申请），还需要安装 socat，使用包管理工具一行命令就能搞定 ，不过我用不到就没有装这个。 安装命令： 1curl https://get.acme.sh | sh 安装好后，重新登陆 ssh 让 alias 生效，可以使用 acme.sh 这个指令，方便操作 安装会写入一条 crontab 定时任务，这就是迷惑人的重点，稍后讲。 注册(issue)工具的用词是 issue，用语和 Let’s Encrypt 对应。在这个工具上，我最终的理解就是注册，有对 nginx 的特殊配置，不会更改配置文件（最终），需要80端口直通（公网ip:80对应机器:80），如果有特殊需求，比如映射端口，那应该是可以的，不过没找到直接描述的手册 1acme.sh --issue -d example.com --nginx 这个语句会注册这个任务，并当即申请一个证书，托管到自己的文件夹下 发布(nginx reload)以下指令，会注册一个任务，任务会将证书发布到指定位置，执行任务所设置的 reload 命令。 nginx 使用的证书需要有完整的证书链，手动处理的话，就是将 CA.cer 和 domain.cer 按照顺序拼装起来，不过这个工具提供了自动手段，配置即可，命令一眼就能看懂不多说。 因为他不会改变 nginx 的配置，所以说发布证书之后，如何使用证书需要自行配置，这个上网找就可以了，不难。 1acme.sh --installcert -d example.com --key-file /etc/ssl/www/example.com.key --fullchain-file /etc/ssl/www/example.com.cer --reloadcmd &quot;service nginx force-reload&quot; 重点这个工具最迷惑人的地方就是他那全自动的系统，那两个步骤执行语句的时候都是当即生效，让人觉得自己要手动执行，甚至考虑要怎么设置定时来执行这两句话，实际上这两句话执行的逻辑是注册，将任务注册到 acme.sh 工具上，然后利用安装时候设定好的 acme.sh 定时任务来执行已注册的任务，所以说实际上只需要执行一次，日后的动作都是全自动的。 为什么当即生效，就理解成添加任务的时候需要一个初始化状态吧 另一个坑在自己的测试环境上，这样就算完成了，但是实际环境上又遇到了一个问题 1Verify error:Invalid response from http://example.com/.well-known/acme-challenge/8VdhXwwueFAe6lqmCpNDtESnkoWiTjhK6afT_nE8hoQ: 怀疑了一圈，最后发现，我们的 http 使用了 rewrite 跳转到 https 的，导致了acme.sh 的配置无法正确更改，有人提出了 issue 但到现在还没有什么措施 所以放弃了使用 –nginx 指令，改用 –webroot 指令，不过这个是否成功，得等过一阵子才能知道，因为写这个说明的时候，提示了这个 1www.example.com is already verified, skip http-01. 可能 Let’s Encrypt 那边有缓存吧，无法得知是不是真的好用了","link":"/2018/02/acme-sh/"},{"title":"62进制转换","text":"代码思路来源于互联网 写下这个的原因是，某日在和别人讨论的时候，产生了这样一个需求： 要有一个六位的字串，容量不能小于1_000_000 不能相邻 乱序分发 经由 dalao 的指点，选取了62进制这种方法，产生一百万条随机间隔的值，存入List，shuffle方法洗牌打乱 写出这段代码，效率不是太高 想到这个东西很多时候都可能会用到，就单独整理出来 注意：62进制，所有人的思路都是，数字09 + 大写字母AZ + 小写字母a~z，共62个，可具体的并没有规定到底先是数字在前还是字母在前，这里可能会发生规则歧义，不要误用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Main { private static char[] dictionary = &quot;0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz&quot;.toCharArray(); /** * 将10进制转化为62进制 * @param rest 输入的10进制字串 * @param length 转化成的62进制长度，不足length长度的话高位补0，否则不改变什么 * @return 62进制字串 */ private static String convertDecimalToBase62(long rest, int length) { Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); StringBuilder result = new StringBuilder(0); while (rest != 0) { stack.add(dictionary[new Long((rest - (rest / 62) * 62)).intValue()]); rest = rest / 62; } while (!stack.isEmpty()) { result.append(stack.pop()); } int result_length = result.length(); // 缺位补0 StringBuilder path = new StringBuilder(); for (int t = 0; t &lt; length - result_length; t++) { path.append('0'); } return path.toString() + result.toString(); } /** * 将62进制转换成10进制数 * @param ident62 输入的62进制字串 * @return 10进制字串 */ private static String convertBase62ToDecimal(String ident62) { Long decimalString2Long = 0L; for (int i = 0; i &lt; ident62.length(); i++) { char c = ident62.charAt(i); for (int j = 0; j &lt; dictionary.length; j++) { if (c == dictionary[j]) { decimalString2Long = (decimalString2Long * 62) + j; break; } } } return String.format(&quot;%08d&quot;, decimalString2Long); } public static void main(String[] args) { // 6位的最大值 56_800_235_583 // 允许的最大值 Long.MAX_VALUE =&gt; AzL8n0Y58m7 System.out.println(&quot;62System=&quot; +convertDecimalToBase62(Long.parseLong(&quot;56800235583&quot;), 0)); // zzzzzz System.out.println(&quot;10System=&quot; +convertBase62ToDecimal(&quot;zzzzzz&quot;)); // 56800235583 //Collections.shuffle(list); // 洗牌，打乱集合 }}","link":"/2017/08/convert-decimal-to-62/"},{"title":"gitlab升级记录","text":"公司用的版本是 8.17.4 ，研发部门用不惯，恰好内网服务器重新部署，决定升级 本文中，所有版本号均为编写时的版本参考，必要的地方贴了地址，记得去看新的文档 本文撰写时，最新版本为 13.5.1，封面截图时最新版本已经是13.6.0，由于没有升级计划，所以并没有使用最新的图 备份首先，备份，并把备份文件拖回本地 备份本体 1gitlab-rake gitlab:backup:create 默认情况下，备份结果会在 /var/opt/gitlab/backups 将配置文件进行备份 /etc/gitlab/gitlab.rb 配置文件 /var/opt/gitlab/nginx/conf nginx配置文件 /etc/postfix/main.cfpostfix 邮件配置备份(可选) /etc/gitlab/gitlab-secrets.json 密钥文件，里面有数据库的密码 升级gitlab 要按照版本逐个升级，官方给出了升级路线， 大概意思就是，跨版本升级，要升级到当前主要版本最新的版本，才能跨入下一个版本 我们的版本是 8.17.4，最终的升级路线为 18.17.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.8.7 -&gt; 11.3.4 -&gt; 11.11.8 -&gt; 12.0.12 -&gt; 12.10.14 -&gt; 13.0.14 -&gt; 13.5.1(当前最新) 极其漫长…… pre首先一个误区，升级不能关闭 gitlab 如果以前改动过某些配置文件，中间可能会有询问，所以盯着点 执行 upgrade 时，系统的部分也会升级，如果用的系统已经不在维护期内，比如ubuntu 1710(我们就是这傻逼东西)，最好先解决系统问题 我的做法是，拉个新虚拟机，ubuntu 1604 lts(截止到2021年4月)，不选1804纯是因为手上只有这现成的，之后会考虑迁移到 centos7.8(EOL 2024年6月) 记得替换源（我用的是 清华） 执行命令时，最好给 ssh 工具开个日志记录，我用的 xshell，记录下过程中的日志，避免出了问题不好排查 各路升级命令很复制粘贴，直接升级上来就行 123456789sudo apt-get upgrade gitlab-ce=8.17.7-ce.0sudo apt-get upgrade gitlab-ce=9.5.10-ce.0sudo apt-get upgrade gitlab-ce=10.8.7-ce.0sudo apt-get upgrade gitlab-ce=11.3.4-ce.0sudo apt-get upgrade gitlab-ce=11.11.8-ce.0sudo apt-get upgrade gitlab-ce=12.0.12-ce.0sudo apt-get upgrade gitlab-ce=12.10.14-ce.0sudo apt-get upgrade gitlab-ce=13.0.14-ce.0sudo apt-get upgrade gitlab-ce=13.5.1-ce.0 感谢多年前部署该系统的人，没有给我留什么配置文件上的大坑 迁移到docker中为了方便日后维护，新开了个靠谱的虚拟机，专门用于 gitlab (以前的gitlab连raid都没有)。 迁移过程如下 配置块存储、mount、fstab、docker/daemon.json、net优化，宿主机该做的都做完后，用 docker-compose 启动 gitlab 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152version: '3.7'services: web: image: gitlab/gitlab-ce:13.5.1-ce.0 restart: always hostname: 'gitlab.vajra.ltd' shm_size: 256M environment: GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.vajra.ltd'; gitlab_rails['gitlab_default_projects_features_builds'] = false; gitlab_rails['lfs_enabled'] = true; nginx['custom_gitlab_server_config'] = &quot;location /-/plantuml/ { \\n proxy_cache off; \\n proxy_pass http://plantuml:8080/; \\n}\\n&quot;; gitlab_rails['ldap_enabled'] = true; gitlab_rails['prevent_ldap_sign_in'] = false; gitlab_rails['ldap_servers'] = { 'main' =&gt; { 'label' =&gt; 'LDAP', 'host' =&gt; 'ldap.vajra.ltd', 'port' =&gt; 389, 'uid' =&gt; 'uid', 'encryption' =&gt; 'plain', 'bind_dn' =&gt; 'cn=admin,dc=vajra,dc=ltd', 'password' =&gt; '123456', 'timeout' =&gt; 10, 'active_directory' =&gt; false, 'allow_username_or_email_login' =&gt; true, 'block_auto_created_users' =&gt; false, 'base' =&gt; 'ou=Users,dc=vajra,dc=ltd', 'attributes' =&gt; { 'username' =&gt; ['uid', 'userid', 'sAMAccountName'], 'email' =&gt; ['mail', 'email', 'userPrincipalName'], 'name' =&gt; 'cn', 'first_name' =&gt; 'givenName', 'last_name' =&gt; 'sn' }, 'lowercase_usernames' =&gt; false } } ports: - '80:80' - '443:443' - '22:22' volumes: - '/data/gitlab/config:/etc/gitlab' - '/data/gitlab/logs:/var/log/gitlab' - '/data/gitlab/data:/var/opt/gitlab' plantuml: image: 'plantuml/plantuml-server:jetty' container_name: plantuml restart: always docker中安装相同版本，然后按照传统步骤执行。 先确保 gitlab-secrets.json 一致 将备份文件复制到 docker 容器的映射目录中 修复权限(因为是直接目录挂载到了容器内，没有用 volume，为的是日后提取东西方便，虽然这样也脆弱了很多) 参考 官方文档-docker恢复步骤，按步骤执行即可 1234567891011121314151617181920212223242526&gt; docker exec -it xxxxx bash# 停止相关服务$ gitlab-ctl stop unicorn$ gitlab-ctl stop puma$ gitlab-ctl stop sidekiq# 检查状态$ gitlab-ctl statusrun: alertmanager: (pid 1001) 1719s; run: log: (pid 695) 1765srun: gitaly: (pid 1021) 1718s; run: log: (pid 301) 1898srun: gitlab-exporter: (pid 626) 1787s; run: log: (pid 640) 1783srun: gitlab-workhorse: (pid 966) 1720s; run: log: (pid 588) 1802srun: grafana: (pid 1029) 1718s; run: log: (pid 745) 1755srun: logrotate: (pid 609) 1793s; run: log: (pid 621) 1789srun: nginx: (pid 591) 1799s; run: log: (pid 602) 1795srun: postgres-exporter: (pid 1010) 1718s; run: log: (pid 719) 1761srun: postgresql: (pid 392) 1893s; run: log: (pid 478) 1891srun: prometheus: (pid 983) 1719s; run: log: (pid 678) 1771sdown: puma: 11s, normally up; run: log: (pid 528) 1814srun: redis: (pid 258) 1905s; run: log: (pid 265) 1904srun: redis-exporter: (pid 976) 1720s; run: log: (pid 659) 1777sdown: sidekiq: 4s, normally up; run: log: (pid 553) 1808srun: sshd: (pid 27) 1925s; run: log: (pid 26) 1925s$ gitlab-backup restore BACKUP=1604455708_2020_11_04_13.5.1 完成上述动作后，重启容器，等待服务正常运转后，执行以下命令 12# Check GitLabdocker exec -it &lt;name of container&gt; gitlab-rake gitlab:check SANITIZE=true 完全通过后，迁移完成，后续升级按照 docker 升级流程，就是按照版本，直接删掉旧容器，换成新的启动，即可 gitlab 配置了 LDAP，这部分之后新开文章记录 FAQ整合后，途中断过一次电，发现 docker 容器整个都丢了…… 虽然不晓得怎么回事，不过好在恢复起来不是太难，重新创建一个容器就好了 但创建容器后，并没有启动，查询日志发现，容器出现了几个问题 权限问题 Permission Denied很容易解决 1docker exec -it gitlab update-permissions Redis RDB 无法读取具体日志忘了存留解决方法也很简单，摸到 redis 日志位置，直接删掉，收工，连容器都不用重启 alertmanager unexpected EOF1caller=main.go:261 err=&quot;unexpected EOF&quot; 解法同上，摸过去删掉，反正 alertmanager 的存储只有告警历史和 since 配置，这些都可以重来 gitlab 的容器十分完备，连 ps aux | grep alertmanager 这命令都能执行，追查起来和宿主机一样","link":"/2020/11/id_983467528/"},{"title":"AJAX在跨域时请求OPTIONS","text":"这个问题早就遇到了，今天又一次遇到而且需要用另一个角度去解决，所以写下来这些总结 AJAX 是个很方便的东西，不过工具性能越好，就会越难以控制，AJAX 就有着种种安全相关的问题，所以浏览器对此做了诸多限制，这些限制也对我们编写带来了一定的约束和限制 最常见的问题应该就是跨域问题，老的解决方法有 iframe, jsonp，但是这两个方法前者有着很大的安全隐患，后者并没有规范标准，很多地方并不兼容而且需要后端对数据做特殊的处理。 如今有了新的 CORS 来解决，十分简单稳定，不过对古董浏览器的兼容性差，在这里不讨论。 先说 CORS 复杂请求的问题： AJAX 请求可以分为简单请求和复杂请求（依照AJAX请求时是否会触发OPTIONS请求来划分，并非 http 规范的称呼） 简单请求需要符合下列三种要求 请求类型为 Get Post 请求的Content-Type为下列三种之一 application/x-www-form-urlencoded multipart/form-data text/plain HTTP请求的头部信息不超过这几种字段 Accept Accept-Language Content-Language Last-Event-ID Content-Type 简单请求，浏览器可以直接发送 具体来说就是自动在头部信息中自动增加一个 Origin 字段用来说明本次请求的源（协议、域名、端口） 如果服务器不允许这个源，则返回结果的 Header 中不包括 Access-Control-Allow-Origin，浏览器没有找到 Access-Control-Allow-Origin 则会让这次请求失败，若允许则返回正常结果集并多出几个字段： Access-Control-Allow-Origin 必须。返回 Origin 字段的值 Access-Control-Allow-Credentials 是否允许包含 Cookie Access-Control-Expose-Headers 默认情况下，AJAX 只能拿到上标准的 header，若需要其他的值则需要这个属性指定，否则无法通过验证 复杂请求，浏览器会先发送一个 OPTIONS 请求，该请求服务器应返回一个 HTTP 204，携带Access-Control-Allow-Origin，同上如果不存在则不允许 复杂请求的OPTIONS可能会返回以下字段： Access-Control-Allow-Methods 必须。返回支持的HTTP请求方法 Access-Control-Allow-Origin 必须。返回Origin字段的值 Access-Control-Allow-Headers 如果请求中包含该字段，则返回时必须有该字段。表明服务器支持的所有头信息字段 Access-Control-Max-Age 用来指定本次预检请求的有效期，单位为秒 Access-Control-Allow-Credentials 是否允许包含Cookie 这些东西，结合返回头部来看会更好，但是目前我没有很好的抓包手段（我指的是抓服务器传入值），等找到更好的抓包方法再进行补充。","link":"/2017/08/ajax-cors-options/"},{"title":"git 配置代理","text":"最近有远程办公的需要，整理了一下如何通过代理使用git 代理是通过 ssh 构建的 socks5 代理，http 还可以用 http 代理，但 ssh 不行，命令不兼容，我懒得去搞那么全 环境 windows，也会提供 linux/mac 的配置 连接 git 的方式有两种，http 和 ssh，两种设置不同，所以分开说 http.proxyhttp 连接的代理不区分系统 git 的配置会写在 %USERPROFILE%/.gitconfig 文件中，命令设置后可以看一眼，很容易懂 如果连接 git 使用了 http 连接，则只需要 http.proxy 配置项即可，最简单粗暴的配置如下： 1git config --global http.proxy socks5h://127.0.0.1:1080 这样不优雅，git 提供了更精细的代理配置，可针对域名设置代理，例如单独为 github 配置代理： 1git config --global http.https://github.com.proxy socks5h://127.0.0.1:1080 修改后，最好看一眼配置文件，明白这其中的细节和原理 ssh proxy如果通过 ssh 连接，代理不归 git 管，而是要配置给 ssh。 这里需要区分系统 windowswindows 的 ssh 配置文件在 %USERPROFILE%/.ssh/config 文件中，如果不存在自行创建，记得删除后缀名。搞不懂后缀名的人，可以通过这个命令来创建文件，记得删除文件中的内容 1echo &quot;&quot; &gt;&gt; %USERPROFILE%/.ssh/config 然后，举例说明，给 github.com 设置代理，配置文件的格式如下 123Host github.com User git ProxyCommand connect -S 127.0.0.1:1080 %h %p linux/maclinux 和 mac 系统，需要使用 nc 工具，请先确保有这个东西。 配置文件在 ~/.ssh/config，可以用类似于 windows 的命令创建文件，不过更推荐直接用 vim 编辑 1vim ~/.ssh/config 123Host github.com User git ProxyCommand nc -v -x 127.0.0.1:1080 %h %p 取消代理很容易的，直接到配置文件中删除掉相应的配置即可。 http 代理可以用以下命令抹除配置： 1git config --global --unset http.proxy","link":"/2020/02/git-proxy/"},{"title":"HTML 中常用的 Meta 标签","text":"整理手机端适配时常用的 META 标签，留作备用 123456789101112&lt;meta charset=&quot;utf-8&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;&lt;meta name=&quot;format-detection&quot; content=&quot;email=no&quot;&gt;&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot;&gt;&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black&quot;&gt;&lt;meta name=&quot;full-screen&quot; content=&quot;yes&quot;&gt;&lt;meta name=&quot;browsermode&quot; content=&quot;application&quot;&gt;&lt;meta name=&quot;x5-orientation&quot; content=&quot;portrait&quot;&gt;&lt;meta name=&quot;x5-fullscreen&quot; content=&quot;true&quot;&gt;&lt;meta name=&quot;x5-page-mode&quot; content=&quot;app&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no,minimal-ui&quot;&gt; 从上到下： 网页字符集编码，这里使用了UTF8 X-UA-Compatible: 文档兼容定义，IE=edge IE以最高模式渲染 format-detection: 规定文中的 telephone, email 和 adress 是否被系统接管，即手机访问时会不会出现点击一串数字跳转到拨号界面 apple-mobile-web-app-capable, apple-mobile-web-app-status-bar-style: 苹果IOS专用，是否使用 web app 标准显示该网页，具体内容 google full-screen: UC浏览器私有 meta，强制全屏 browsermode: UC浏览器私有 meta，页面默认全屏（会覆盖系统状态栏），禁止长按菜单，禁止收拾(?)，标准排版，以及强制图片显示 x5-orientation: QQ浏览器私有 meta，屏幕方向 x5-fullscreen: QQ浏览器私有 meta，设置全屏 x5-page-mode: QQ浏览器私有 meta，设置屏幕模式（会保留系统状态栏） viewport 显示设置: width: 宽度，device-width 设备宽度，值和body给了CSS 100%相同 initial-scale, minimum-scale, maximum-scale: 初始缩放比例、最小缩放比例、最大缩放比例，全是1则禁止缩放（不完全） user-scalable: 用户缩放 no则禁止缩放，配合上条完全禁止缩放 minimal-ui: IOS7专用标签，隐藏工具栏、地址栏，IOS8 废弃 META标签的属性:对于META标签，必要的属性只有一个content，用于声明描述内容 所描述的选项可以由两种属性来声明 name http-equiv 其中http-equiv会将该条META写入请求Header中，用法多样，比如设置缓存、刷新时间、请求类型等 SEO相关1234&lt;meta name=&quot;keywords&quot; content=&quot;your keywords&quot;&gt;&lt;meta name=&quot;description&quot; content=&quot;your description&quot;&gt;&lt;meta name=&quot;author&quot; content=&quot;author,email address&quot;&gt;&lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;&gt; 大概从英文是可以看出功能 keywords，页面关键词 description，页面内容描述 author: 作者 robots: 告诉搜索引擎索引对网站的索引程度，默认值为index索引本页面，可以设置多个值，除此之外有如下常见值（不完全） noindex: 禁止搜索引擎索引 noimageindex: 禁止搜索引擎索引本页面上的图片 follow/nofollow: 允许/不允许爬虫去爬本页面上的链接 none: none是noindex,nofollow的缩写 noarchive: 阻止搜索引擎显示该页面的缓存版本，就是快照 nocache: 同上 DNS 预读取12&lt;meta http-equiv=&quot;x-dns-prefetch-control&quot; content=&quot;on&quot;&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;//www.spreadfirefox.com&quot;&gt; 可以强制让页面内加载时，同时请求列表中的 DNS，让浏览器提前缓存目标 url 的 DNS 解析，减少请求时间 使用场景： 一些静态资源域名(超链接浏览器会自动处理) 登录页面，可以将要访问的地址和即将跳转的地址加入，加快请求速度 该参数还可以使用 Header 来赋予","link":"/2017/04/html-meta-tag/"},{"title":"关于自动拆箱的缓存性质研究","text":"在使用中会发现，int与其对应的包装类Integer做 等比较 时，会发现，值在 -128~127 间，可以产生true，但在范围外就会产生预期之外的false，翻看 valueOf() 源码 12345public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache\\[i + (-IntegerCache.low)\\]; return new Integer(i);} valueOf()装箱是有缓存机制的，缓存的范围定义在 IntegerCache 类中，low 为固定值-128，high 默认为127，可以通过 sum.misc.VM 这个类，即 JVM 参数 -XX:AutoBoxCacheMax 配置 12345678910111213141516171819202122static { // high value may be configured by property 可以通过配置VM设置更高的值 int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // 在这里决定了这个缓存最大值至少设置为127 // Maximum array size is Integer.MAX_VALUE 最大数组容量是Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. // 如果该属性无法作为 int 解析，忽略它 } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) 范围[-128,127]必须是实体的（JLS7 5.1.7） assert IntegerCache.high &gt;= 127;} 这个的缓存机制是在static区设置一个数组，容量为128 + IntegerCache.high ，内容为 -128 ~ IntegerCache.high ，被缓存的 Integer 对象中的值引用设置到该数组上，所以做 等比较 时，会产生相等的现象，因为引用相同。 编写一段测试代码 123456789public static void autoBoxTest(){ int i1 = 127, i2 = 200; Integer integer1 = i1; Integer integer2 = i1; Integer integer3 = i2; Integer integer4 = i2; System.out.println(integer1==integer2); // true System.out.println(integer3==integer4); // false} 添加 -XX:AutoBoxCacheMax=256，增大缓存范围，结果变为 // true true 代码分析中已经得出，AutoBoxCacheMax 必须大于127，小于127会自动设置为127。","link":"/2017/04/java-autobox/"},{"title":"Java中的位移运算","text":"java中位移运算符可参考 C 中位移运算，但 Java 中较 C 多出一种无视符号位的位移 13&gt;&gt;&gt;1 意思为，忽略符号位进行位移 会忽视符号位的影响（如负数位移补码中补位的是1） Java中，对于位移负数位有特别算法 例如： 13&gt;&gt;&gt;-2 其实等价于 13&gt;&gt;&gt;30 位移负数，取位移数后五位（long，double取6位），二值化，忽略符号位， 1234数字2二值化： 0000 0010 =&gt; 2取负数 补码： 1111 1110 =&gt; -2取出后五位： 111\\|11110 =&gt; -2十进制化： 11110 =&gt; 30 做这种转换后，得出移动值","link":"/2017/04/java-shift-operators/"},{"title":"arthas使用记录","text":"前些日子遇到了一次线上问题，新部署的机器，还没有流量，浏览器页面第一次打开耗时极其过分(10s~40s)，机器没崩人先疯了。 几个命令下去，机器内存、cpu、IO 负载等参数表示机器很闲，所以怀疑是代码问题 浏览器 devTools 上显示请求耗时都在 TTFB 上 当时看着代码怀疑了一圈又一圈，尝试在本地 debug 复现，折腾了两个小时，复现失败。 然后尝试找某种监测方法调用的工具，搜到了几个不同种类的工具，btrace、jvm-sandbox、arthas、greys，这几个工具都十分的强大，不过最终我选用了arthas，当然理由很肤浅只是因为中文手册容易阅读（救场如救火） 思路实际上这篇文章，只是为了记录下排错的思路，具体的操作当时没有记录下来 这个工具能实现排查链路中每个调用的耗时情况，当然并没有递归(可能别的工具有)，所以只能定位过滤到的方法内的调用。 不过基于这点，就可以解决许多的问题了 好了，本文完结，下面的是我事后整理的过程。 计算方法调用的耗时和链路上的耗时，使用trace命令加#cost筛选时间，这个命令可以打印出调用列表和每个方法调用的耗时 定位到某个耗时很大的方法上，大概就达成80%了，毕竟这种原因不明的问题，找到问题比解决问题更难 实际上我这次使用已经结束了，我监测的是入口，直接定位到了耗时极大的getSession()方法，然后怀疑是tomcat生成sessionId的时候调用的Random性能不足，替换为 /dev/./urandom 问题解决 如果你发现这条链路上耗时极大的方法可能有多个调用来源，那就使用stack来抓取调用链，可以找到调用来源 精确定位好后，用watch抓取方法入参和出参 大概就这些了 后记文章相当短，这工具我也只摸了皮毛（救场如救火） 只能说自己无知，有这方面经验的人直接就会想到用这类工具排查，不会绕这么大个弯子。这次经验也算是给自己增加了一种排错手段 至于当时遇到的问题到底是啥？ tomcat, 云服务器部署，默认使用了 /dev/random，云服务器可能没有做处理，熵池亏空，导致了在生成 session 这个步骤时产生了阻塞。最终解决方法，已经时江湖广为流传的，-Djava.security=file:/dev/./urandom 2019.01.04：唯品会的白衣大大曾经还详细分析过这个问题，在这里贴上原文：SecureRandom的江湖偏方与真实效果","link":"/2018/12/jvm-arthas/"},{"title":"Let&#39;s Encrypt 通配符证书","text":"3月14日，Let’s Encrypt终于开通了通配符(wildcard)证书的申请。其实这个东西没什么好记录的，无非就是打开工具申请证书，通过DNS验证域名所有权，也算是体验下通配符的省力了，直接覆盖所有二级域名。 这可能是我写过最短的一篇博文了。","link":"/2018/03/lets-encrypt-wildcard/"},{"title":"博客更换至caddy","text":"最近想要搞一个下载文件的页面，又不想自己写前端，nginx 的 autoindex 太难看，想要使用 fancyindex 却还需要编译 nginx 才能开启这功能，目前在 docker 上懒得自己搞，想起了 caddy 这个东西带这个功能并且还算看得过去，就有想法去搞 caddy。 beforeCentOS7 docker，nginx 使用了官方 docker 镜像 暴露80、443端口，挂载本地文件夹，网页内容放在本地，配置方面也只是设置了 http -&gt; https，还有 TLS 证书，证书使用 Let's Encrypt 通配符证书，开启 http2，算法方面该默认都默认没有什么特殊的 afterCentOS7 docker，caddy 使用了 abiosoft/caddy 暴露80、443端口，挂载本地文件夹，使用 caddy/git 插件拉取 github 仓库内容，方便日后更换博客前端，也方便当前 hexo 内容同步，稍后把 github 的 homepage 改到自己的域名上 caddy 配置了自动的 TLS 证书，默认开启 http2 (不过在我浏览器上，http2并没有生效，SSLlabs倒是通过了，可能本地环境问题)，默认使用 TLS 1.2，想要使用 TLS 1.3 需要自行编译 golang 运行环境，想要启动 QUIC 需要手动加一个启动指令，不过这个 docker image 没提供这个，想搞就要自行 build 一个，或许过几天手痒痒就去搞起。 赠品caddy 的文档，建议去看官方文档，英文也没几个词翻翻字典就当学英语了 官方文档中文翻译文档-旧","link":"/2018/12/migration-to-caddy/"},{"title":"用 wifi 模块配合继电器远程开机","text":"为了给主板做远程开关机，搞了这么一个玩具 实际上想要实现该目的，有以下几个方案 Wake On Lan(WOL) 技术成本最低，但技嘉的主板想打开这个需要关闭快速启动以及一大堆的东西，很反感。 论实施成本，找个远程控制的智能插座，配合主板的掉电处理，也能实现目的，只不过自己用电脑想开机，也得通过这个，体验很差 最近比较闲，买了几个 wifi 模块，配了个继电器，搞起了这么个玩具 先声明，我不是专业玩单片机、嵌入式、物联网设备的，下文可能有许多不专业的地方，虚心请教，望好心人指出。 物料清单 esp-01s(esp8266)，淘宝10块包邮 esp-01s 继电器模块，淘宝10块包邮 ttl 刷机工具，淘宝5块包邮 图中是esp-01s 继电器模块，不要在意那两个裸漏的线 玩法esp8266 这个模块，十分的便宜，脚位齐全、搭配 ch340 串口芯片的开发板也只不过14块包邮，简化引脚的 esp-01s 更是 8 块都不到 80/160Mhz主频，80k ram，1Mbyte 或 4Mbyte rom，乐鑫官方甚至提供了 FreeRTOS 操作系统固件，虽然我不会用 生态十分齐全，当作玩具来玩的话，有 c、python(MicroPython)、javaScript(Espruino)、Lua(NodeMCU) 语言可选，资料很全 远程控制方案，我选择了mqtt下发消息，模块改写引脚电平，触发继电器 就这么点功能，用什么语言写也就十几行的样子，不过最后我选择了 Espruino，随便写了一下，算是实现了功能 选用一些实时操作系统，比如 FreeRTOS、RIOT，都要用 linux 系统，交叉编译之类的，手上的 linux 都是服务器版，这点需求懒得折腾 零碎的点 esp8266 均采用 3.3v 供电，刷写固件时官方要求电流为200ma，一般的 ttl 模块供电都足够，不过我用了辣鸡的 usb2.0 hub，供电不足，刷写成功但过不了开机的 checksum，刷了几次，概率性失效，最终换到了主机上的usb孔，解决问题 连接wifi，最简单的方法就是直接输入 SSID 和 password，但是 SSID 如果涉及非 ASCII 内容，需要按UTF-8输入，否则连不上。 wifi 天线增益很小(esp-01s是印刷天线，估计是2db的)，太远了 mqtt 就会各种断线，虽然 mqtt 会重连 esp8266 的 ttl 启动时会有启动 log，可以看到一些硬件相关的初始化信息，但波特率在 74880，直接用 115200 会表现为一堆乱码启动成功后，官方固件可以使用 AT 命令测试一下是否可用，发送 AT 应该会返回 OK，查看当前固件信息的命令为 AT+GMR ESP-01s 的 GPIO2 是绑定了指示灯的，也就是改动 GPIO2 引脚 如果用 C 语言，是支持 OTA 的，其他几个语言的环境似乎没有这个功能，Espruino 的代码是通过 ttl 写入的，类似于浏览器，并不需要烧录即可变更代码，并且提供了 ttl 封装重定向的相关内容。 Espruino，执行代码很像终端(实际上就是个终端)，IDE 的原理是把代码执行一遍，执行过后需要自己写保存动作，否则重启就会重新初始化。不过 wifi 相关的信息，是写在硬件中的，调用 save(); 之后就不会丢失。 所以代码可以遵循一个模板 12345678function init() { // some code}E.on('init', function () { init();});save(); Espruino 的 telnet，如果使用 XShell，有时候就会出现类似下图的 EOF 异常，这个可能是 telnet 实现不完全或者客户端混入了奇怪的字符，输入前先按一下 Ctrl + C，就没事了不过使用 windows 自带的 telnet，会有回显，很是别扭，或许可以用命令关掉回显。 过程和成果起初购买继电器和模块时，贪便宜翻车了。 淘宝上能找到的版本有两种，v1.0，v4.0，两者引脚定义应该是一致的，最开始买到了 v1.0，但这个版本默认给 GPIO0 下拉，通电进入下载模式，测试 GPIO0 插槽到 GND 有1.24v 电压，认定翻车了。 IO接线什么的，随便搜一下就有，如下图 最终成品大概是这样，ttl 供电测试，不要在意 软件部分，选用 mqtt 下发命令，触发代码更改引脚状态。 ESP-01s 的引脚很少，GPIO0, GPIO2, RX, TX，淘宝的模块都是 GPIO0 触发 所以，整个的折腾流程就是这样： ttl 刷写 Espruino 固件 搭建 mqtt 服务端，我选用了 EMQX，十分专一的 mqtt 服务器，曾经在线上用过的技术，比较熟悉 引入 tinyMQTT 代码库，编写业务代码 GPIO0 和 GPIO2 同步操作，这样可以通过板子上的灯观察结果 装板，测试继电器通断 先来个 Hello world 然后写入代码，存进去。 最终运行状态 Bug因为模块的因素，通电时会有一次的继电器闭合，所以给电就会触发一次，目前还不晓得怎么处理","link":"/2020/04/remote-relay/"},{"title":"迁移至Hexo","text":"前阵子自己用Vue.js写了一个博客，自己火候还是不太够，写的很不满意 无奈还是搬回了Hexo，迁移的时候索性时间都复制了过来 先用着吧，有时间把前端再拿起来，重新写一份","link":"/2017/07/move-to-hexo/"},{"title":"端口连通性测试","text":"此文送给刚开始折腾服务器的小伙伴 有时候，端口无法访问，可能出现的问题很多。 排查要按照章法来，这是我自己总结的流程，不是太完全但大概够用，有些环境没有那么多环节，自行过滤。 检测端口监听 保证端口在最近的点(localhost)可用 检查防火墙、SELinux 检查安全组（云服务器） 检查服务端交换机转发、出入规则（一般人用不到） 检测本地段是否禁止出流量（受限制的网络环境） 检查一下自己脑子是不是坏了 如果某一行你完全不懂又在这说我讲得太难，那直接选择最后一行，考虑考虑是否需要退出这个行业。 检测端口监听首先要保证端口开启，最简单的方法就是使用 netstat, ss 这两个工具。ss 限于 linux，参数用法自行查找根据系统不同，命令参数和用法都有不同，这里列举几个常用的命令供大家复制。 windows: 12345678直接打印出所有端口情况，-o 打印出使用端口的 PID。如何使用 PID 自行百度netstat -ano指定查 8080 端口情况netstat -ano | findstr 8080查询所有 TCP/UDP 端口情况netstat -ano -p tcp/udp Linux: 12345678直接打印出所有端口情况，-p 打印出使用端口的 PIDnetstat -anp指定查 8080 端口情况netstat -anp | grep 8080仅查看 tcp 端口监听情况(注意是监听)，udp 把 t 换成 unetstat -nltp 使用该工具可以查看到端口状态，其中，LocalAddress 列可以看到监听是在哪一个网段 这时候关注的端口如果是 LISTEN 状态，并且监听的网段是自己需要的网段，就没有问题(不懂的话去查查 ipv4 如何划分网段的，以及子网掩码怎么用) tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 851/sshd 一般人会见到的情况有两种(如果你用docker或者其他容器技术，另讲)，拿 sshd 为例，0.0.0.0:22 或者 127.0.0.1:22，前者任何网卡都通，后者只能在回环地址上用(也就是本机) 如何测试端口是否可达确保端口监听后，就要在不同的点测试端口是否可用。若不可用，先检查端口是否可达，再检查端口业务是否正常 如果端口在最远端不可达，就先去最近端检查可用性，确保端口和业务是真的可用。 tcp端口可达很容易测，只需要使用这个十分常用的工具 telnet 即可，这个工具目前不是系统自带，需要安装一下，具体过程自行查询 telnet 基于 socket(写IO的人都知道)，典型的应用是可以检测 ssh 端口和 http 端口是否可用，这对于排查防火墙、安全组等问题很有用处。 1telnet [ip] [port] 但是 udp 端口很难检测，telnet 可以做 tcp 握手，但是 udp 无法实现。 实际上也有一个工具，虽然不是做这个功能的，但是可以实现排查 udp 端口是否可达，这个工具就是 nc(ncat) 不过这个排查思路不同于 tcp，只能检测端口是否可达，无法检测业务是否正常 nc 是个网络工具，可以绑定某个端口用来接收，另一端同样用 nc 发包，这工具可以检测某个 udp 端口被防火墙丢弃或者被中间路由封锁。 如下命令可构成一个 udp 发送通道 12345服务端：nc -u -l -p 4000客户端nc -u 10.0.0.2 4000 比如 4000/udp 是 QQ 需要的端口，检测网络环境是否封禁 4000/udp 就可以在服务器上开监听端，自己电脑使用客户端 这个工具也可以检测 tcp 连通性，把 -u 去掉即可 剩下的排查思路这篇文章就是个入门教程，工具用什么都好，关键是思路。 网不通先要考虑机器是否可达，可达的情况下就要一步步排查中间环节是否连通 至于业务怎么检测可用，那应该问端口业务 不好归类的东西有一些可能用到的其他工具，怎么用自行搜索吧 抓包工具： tcpdumptcpdump -nl -A port 1883 常用的网络检测工具： mtr等同于同时使用 ping, tracert, nslookup","link":"/2020/04/port-connectivity/"},{"title":"排序备忘","text":"对前阵子玩的排序做了一下总结，目前已总结了 冒泡排序 选择排序 快速排序，堆排序和归并排序目前还没有吃透，桶排序写出来效率感人，也试过多线程的排序发现效率十分感人，就不拿出来献丑了 冒泡排序最简单的排序算法，重复走访所以要排序的元素，每次比较两个相邻元素，如果顺序错误则调换。这个算法两端的极值会逐渐“浮”到应到的位置，所以起名冒泡排序。 过程如下： 比较相邻元素，若顺序不符则调换 对每一个元素执行这个过程 代码如下： 123456789for (int j = 0; j &lt; arr.length - 1; j++) { for (int i = 0; i &lt; arr.length - 1; i++) { if (arr[i] &lt; arr[i + 1]) { int temp = arr[i + 1]; arr[i + 1] = arr[i]; arr[i] = temp; } }} 选择排序对冒泡排序的一个改进版本，每次遍历选出最小值/最大值，在本次遍历结束时放置到应摆放位置，效率高于冒泡排序。 过程如下： 遍历，选出最小值/最大值 将最小值/最大值放置在已排序区 代码如下 1234567891011for (int i = 0; i &lt; arr.length; i++) { int min = i; for (int j = i + 1; j &lt; arr.length; j++) { if (arr[min] &gt; arr[j]) { min = j; } } int temp = arr[min]; arr[min] = arr[i]; arr[i] = temp;} 快速排序利用分治思想，对冒泡排序进行改进。选出一个轴点，对待排序区进行遍历，遍历结束保证轴点左方均小于等于轴点，右方均大于轴点，然后依照轴点进行分治。效率理论上远远超过冒泡和选择。该排序为不稳定排序，适合于数量较大、重复较少的情况 目前对快速排序的理解只能止步于这个层面，看了很多网上的代码，也没能再一步改良这个。 过程如下：分治开始 选出轴点（一般为待排序区第一个） 遍历待排序区 若该值小于轴点，则将该值放入小于轴点的区域 若该值大于轴点，则将该值放入大于轴点的区域 将轴点放在小于轴点区和大于轴点区之间 依照轴点前后，分治（一般为递归法） 自己写的代码： 12345678910111213141516171819202122232425262728293031323334353637383940/** * 快速排序 * * @param i 待排序数组 * @param start 待排序区域起点 * @param end 待排序区域终点 */private static void quickSort(int[] i, int start, int end) { // 节省运行次数，但会带来一个缺点，待排序区只有两个数值时，排序不会执行, if (start + 1 &lt; end) { // 边界点 = 轴点 + 1, int mid = start + 1; // 遍历, for (int t = start + 1; t &lt; end; t++) { // 小于轴点，边界点后移，将值归入界点范围, if (i[start] &gt; i[t]) { if (t &gt; mid) { int tmp = i[t]; i[t] = i[mid]; i[mid] = tmp; } mid += 1; // 大于轴点，将该值移动到界点后, } else { if (t &gt; mid) { int tmp = i[t]; i[t] = i[mid]; i[mid] = tmp; } } } // 将轴点放在两个区域中间，对换轴点和边界点, int t = i[start]; i[start] = i[mid - 1]; i[mid - 1] = t; // 分治, quickSort(i, start, mid - 1); quickSort(i, mid, end); }}","link":"/2017/08/sort/"},{"title":"SSL证书配置","text":"最近给自己的域名弄了SSL证书，却也不难，Let’s Encrypt的证书，免费，几分钟就可以弄下来。至于SSL证书是什么、DV证、申请证书的方法很多这里不做讲解，想知道的话，百度就行了（这种问题都不必去问谷歌）。 接下来说下我遇到的一些问题 首先我的证书是使用www.sslforfree.com 申请的Let’s Encrypt，nginx做静态服务器，下发的压缩包中有三个文件，分别为ca中间证、域名证书、私钥 ca_bundle.crt certificate.crt private.key 直接将域名证书 certificate.crt 配置后，能通过浏览器，但是使用curl无法通过，报错为 1curl: (60) SSL certificate problem: unable to get local More details here: https://curl.haxx.se/docs/sslcerts.html 这个错误的原因基本就是，CA里没有根证书或者没有中间某层的证书（不晓得浏览器为啥没事） 此时使用openssl验证 1openssl s_client -host &lt;host&gt; -port 443 会在前几行出现这个错误： 1verify error:num=20:unable to get local issuer certificate 还有这个 1verify error:num=21:unable to verify the first certificate 这两条和上面一样，不过理由明确了，无本地证书，无法验证当前证书，也就是说我缺少一个证书。。。（还是不知道缺哪个） 仔细观察证书信息，web的证书有一层中间证，在申请之后也随压缩包下发了，即 ca_bundle.crt，使用 1openssl verifly &lt;file&gt; 验证两个证书，发现ca_bundle可以通过，而web会显示缺少上级证书 问题明确了，验证的链路上缺少的就是这个中间证（verify可以验证当前证书能否通过验证，若缺少证书即签署该证的证书不存在） 然后我们将两个证书装在一起，构成证书链，注意顺序 nginx启动时出现这个错误： 1X509_check_private_key:key values mismatch 这个错误即当前证书无法验证，大多数都出现于拼装证书时顺序错了，调整下顺序即可。","link":"/2018/01/ssl-cert/"},{"title":"Thinkpad E440 Hackintosh Files","text":"ReadMeThis is related to OS X repositories. Only support Lenovo Thinkpad E440 20C5A08ECD. Other models are not applicable. This repositories contains: battary-patch Clover-config kext-list DSDT-source OverviewWorking Intel HD4600 Graphic Brightness to Shortcut HDMI support (But HDMI audio can not use) Disabled NVIDA Geforce graphic card under DSDT Cabel Network Support SpeedStepping Sleep USB Not Working internal WIFI cark: RTL8723 not solution USB not integrated: Shutdown change to restart HDMI Audio not working CONEXANT CX20751/2 Audio (not work to use AppleALC) USB 3.0(just a few problems) ReleasesClick to Download Releases Versions: 2019-09-20: update to 10.14.5(Mojave) update Clover to r5070; update all kext and update all driver Upgrade to the new graphics driver methods remove to SD Card Reader(driver norenew) 2017-03-11: Fix Shutdown starts up again(Need change BIOS setting) Add SD Card reader driver thnxSinetek(RTS5227 ID: 0x522710ec) Updata Clover to 4012 2017-02-18:Initial version Realized some moudle include graphic, audio, cable network, keyboard and touchpad Disable Discrete Graphics on DSDT HDMI support (But HDMI audio can not use) Keyboard adjustment(Reference to document) Sleep support(More than 2 hours will be black screen) How to fix ShutdownTurn off about Network Wake setting in BIOS How to use itDownload this and according to Clover boot. FeedbackIf you have any question, Plese do not hesitate to contact me by using the issue function. thanks toClover Team RehabMan Sinetek pcbeta forum’s users and more OS X hacker LicenseThe source code is released under GPL v3 or (at your option) any later version.","link":"/2017/03/thinkpad-mac/"},{"title":"SpringMVC @RestControllerAdvice遇到的坑","text":"其实也说不上是坑，最近在配置框架时使用到了这个注解来最终错误处理 但是配置过程中发现了这个注解的问题 先说说场景，目前有两个标注 @RestControllerAdvice 的类，类和类下面注册的异常分别是： 1234GlobalExceptionAdvice:|-ExceptionAppExceptionAdvice:|-OtherException 实际已注册异常比这要多。这时触发 OtherException ，发现响应错误的是 Exception 的 handler 也就是说， OtherException 的 handler 失效了 最初怀疑是注解扫描没有扫描到 AppExceptionAdvice，给 bean 的 Construct 里打印日志，证明了 bean 被初始化 也就是说，明明被扫描了AppExceptionAdvice，却一点也没起作用。 不过在日志中看到了如下两条日志 1218:43:27.352 INFO -- [on(2)-127.0.0.1] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in globalExceptionAdvice18:43:27.353 INFO -- [on(2)-127.0.0.1] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in appExceptionAdvice 考虑可能性，一个覆盖了另一个，或者说先注册的占据了先机，判断异常时产生了这个情况。 打开 debug，抛出错误，在 Exception 的 handler 中抓取，查看调用栈，找到了 ExceptionHandlerExceptionResolver.doResolveHandlerMethodException() 方法，调用 handler 的方法就是这个。 以下代码基于 SpringMVC 4.3.11.RELEASE 1234567891011121314151617181920212223242526272829303132/** * Find an {@code @ExceptionHandler} method and invoke it to handle the raised exception. */@Overrideprotected ModelAndView doResolveHandlerMethodException(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod, Exception exception) { // getExceptionHandlerMethod 负责找到处理异常的Handler ServletInvocableHandlerMethod exceptionHandlerMethod = getExceptionHandlerMethod(handlerMethod, exception); if (exceptionHandlerMethod == null) { return null; } exceptionHandlerMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); exceptionHandlerMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); ServletWebRequest webRequest = new ServletWebRequest(request, response); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); try { // 负责执行handler if (logger.isDebugEnabled()) { logger.debug(&quot;Invoking @ExceptionHandler method: &quot; + exceptionHandlerMethod); } Throwable cause = exception.getCause(); if (cause != null) { // Expose cause as provided argument as well exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, exception, cause, handlerMethod); } else { // Otherwise, just the given exception as-is exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, exception, handlerMethod); } } // other code} ExceptionHandlerExceptionResolver.doResolveHandlerMethodException() -&gt; getExceptionHandlerMethod() 下面这段代码用于寻找可适配当前 Exception 的 Method，由 LinkedHashMap 存放，这里就和顺序有关联了 12345678910// 这里的 exceptionHandlerAdviceCache 是个 LinkedHashMap，存放了已注册的 Advice 类和一个 Cache，Cache 不是分析目的for (Entry&lt;ControllerAdviceBean, ExceptionHandlerMethodResolver&gt; entry : this.exceptionHandlerAdviceCache.entrySet()) { if (entry.getKey().isApplicableToBeanType(handlerType)) { ExceptionHandlerMethodResolver resolver = entry.getValue(); Method method = resolver.resolveMethod(exception); if (method != null) { return new ServletInvocableHandlerMethod(entry.getKey().resolveBean(), method); } }} 确定了顺序相关，就要考虑顺序是如何确定的。实际上这时已经可以考虑到使用 @Order 来解决问题 继续追查代码，顺着resolver.resolverMethod() -&gt; resolveMethodByExceptionType() -&gt; getMappedMethod() 方法，我们可以找到如何将当前异常对应到具体方法的代码逻辑，这个方法在ExceptionHandlerMethodResolver 中 123456789101112131415161718192021/** * Return the {@link Method} mapped to the given exception type, or {@code null} if none. */private Method getMappedMethod(Class&lt;? extends Throwable&gt; exceptionType) { // 传入参数为当前错误， List&lt;Class&lt;? extends Throwable&gt;&gt; matches = new ArrayList&lt;Class&lt;? extends Throwable&gt;&gt;(); for (Class&lt;? extends Throwable&gt; mappedException : this.mappedMethods.keySet()) { // this.mappedMethods 中存放了当前handler中的所有方法 if (mappedException.isAssignableFrom(exceptionType)) { // if条件会选出处理与入参类相同或为超集的类的方法，List存放结果 matches.add(mappedException); } } if (!matches.isEmpty()) { // 将结果进行排序，并返回第一条结果对应的方法 Collections.sort(matches, new ExceptionDepthComparator(exceptionType)); return this.mappedMethods.get(matches.get(0)); } else { return null; }} 到了这里，大概的性质就摸清楚了 总的来说，就是从 getExceptionHandlerMethod() 方法选出一个 handler，然后再这个 handler 内选出 method 用来处理这个异常。 这样就会造成一个问题，即排位靠前的 handler 内若是有这个异常的超集，那就轮不到排位靠后的 handler，导致了我所遇到的问题。 从现象看本质，再从本质制定规范。 如果要使用多个 handler，就像我这里有一个 globalExceptionHandler，那就要使用 Order 手动控制扫描顺序，默认情况下 Advice 注解的 Order 为最低优先，大部分的 bean 都是这样。 因为 globalExceptionHandler 优先级已经是最低了，我们只能去提高业务层 handler 的优先值。 同一个异常线，必须在同一个handler中，不然会出现被超集适配走的情况 或者干脆放弃使用 globalExceptionHandler 这个方案做兜底的异常处理，改为定制 springmvc 返回异常的处理器，这样对业务入侵为0 剩下看个人吧","link":"/2018/04/springmcv-advice/"},{"title":"迁移到 Mac","text":"最近重新搬出了黑苹果，打算把工作环境迁上去。 有些东西还是挺麻烦的，本想直接安装 docker 解决一些环境问题，后来觉得这玩意，笔记本内存并不大，也就只能拿来启动个 mysql，放弃了 docker HomebrewMac 系统中的 apt、yum，感觉应该是个十分方便的东西。可是实装后，我用来装了个 node，就出了许多问题 node 装好后没有 npm，不晓得是不是我版本的问题 不能很好的定制版本，至少没有让我这个没接触过的很容易的选择版本 软链接还出了问题，虽然提供了解决方法，但是你都提供方法了为啥不自己修复一下 总而言之，体验不好，最后node环境还是手工解决的，LTS版本 本想用来装个Java，然后发现里面并没有Oracle jdk，emmm…… 到最后还是自行下载了pkg版本，虽然确实想试试 openjdk 来着 不了解Mac的服务管理，最后选择了手动下载二进制MySQL iTerm2 + Oh My ZSH这个组合是一个产品小哥和数据大佬的推荐，Oh My ZSH实装之后觉得，zsh可定制性和各种插件好评，虽然我也用不上什么，不过tab的提示和自带主题真的可以 然而iTerm2就只能说一般了，没感觉到那种眼前一亮，跟系统自带的相比功能也好强度也好，也就那样，可能我还是用不到那些高大上的功能。 常用工具 IntelliJ IDEA Ultimate直接用 Jetbrains toolbox 安装，省时省力，还有中国 CDN，就是速度很看人品，太慢的话暂停重开可能就会好 VSCode微软爸爸的记事本，轻量级开发 IDE，插件很多，底层据说是 Atom 魔改过的，不过那跟我没啥关系 印象笔记安卓、win、mac 三平台同步，虽然最近没写过什么正经笔记 Chrome重度谷歌用户必须要有的东西，安卓、win、mac 三平台同步，什么都方便如今也能在国内直接下载了 SS用谷歌的怎么能没有这个，顺便一提最近打算自己架设线路，如有定时的轻度用户欢迎合作 微信、QQ必须要有的聊天工具，不然自己就像与世隔绝了一样 MacDownMac 系统上的 markdown 编辑器，在我心中他只是第二，mou 还是比这个好用，可惜 mou 只支持到10.11不过最近也很少用这东西，反而是 VSCode 一步到位了 AlfredMac 上的神器，能设置许多的方便功能，强于 Mac 的 Spotlight。我加装了有道插件、几个快捷启动、颜色编码识别插件。不过收费产品，暂时还没宽裕到支持正版，请允许我厚颜无耻一次。win 上的 Wox 就是参照这个软件的模式做的。 officeoffice365 套件，跟 win 上用的同一套，一个账户直接通用 朋友推荐的东西这里的东西我并没有使用 Quiver用于代替印象笔记，markdown编写，笔记该有的他都有，是个中国人开发的有GitHub仓库不过没开源，收费软件，再加上没有印象那么强劲的全平台，而且我印象会员还有很久，就没考虑 MWeb比上面那个更强的笔记软件，markdown编写，还支持生成hexo博客，IOS和Mac客户端，也是中国人开发的，看着官网感觉不错，可是理由同上。 如有其他日后补充。","link":"/2018/04/transfer-to-macos/"},{"title":"VS Code 使用记录","text":"本文记录个人使用 VS Code 时发现的易用插件、遇到的问题、解决方案。 长期更新 配置、插件 同步插件 Settings Sync最近发现了一个好东西，可以借助 github gist 给 vscode 提供一个配置同步，这款插件名为 Settings Sync 使用十分方便，在新安装好的 vscode 上安装这款插件，登录 github 账号，并配置 gist 地址，就可以同步配置 Markdown 转换为 PDFMarkdown 转换为 PDF 的思路，是借助工具，转换为 html，然后通过浏览器的 打印为 PDF 生成 PDF 文件 1markdown -&gt; html -&gt; pdf 方案可行，缺点是不灵活，虽然写成脚本也没差。 为此诞生了很多方便的工具 这里记录一款 vscode 的插件 yzane/Markdown PDF 扩展，可以很容易的将 markdown 转换为 PDF。 注意：这个工具依赖于 chromium，说白了就是要个浏览器。插件安装后会自动下载 Chromium，但是很慢，而且很大，如果电脑中有 Chrome，可以直接配置以下信息 1&quot;markdown-pdf.executablePath&quot;: &quot;C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe&quot;, 让插件使用现有的浏览器，节约时间节约空间。 顺便还有一些我平常使用的配置： 123456&quot;markdown-pdf.styles&quot;: [ &quot;markdown-pdf.css&quot;],&quot;markdown-pdf.executablePath&quot;: &quot;C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe&quot;,&quot;markdown-pdf.includeDefaultStyles&quot;: false,&quot;markdown-pdf.displayHeaderFooter&quot;: false,","link":"/2020/02/vscode/"},{"title":"常用环境 mirror 地址","text":"主要覆盖了我可能会去使用的 mirror。长期更新。 前端 node 管理以及常用 mirror 地址总共分三个部分，nvm、npm、其他镜像 我选镜像的原则是，阿里、华为、清华，哪个好用就哪个 最近没有对 yarn 的使用，这部分暂且省略 nvm对于安装 node 环境，无论是 win/Linux，均推荐使用 nvm 安装环境，方便、稳妥、麻烦少 目标环境 node LTS 版本 npm 而非 cnpm (个人不喜欢cnpm) (可选) yarn 包管理工具 安装位置均为默认位置，对 C盘 有强迫症的，请自行前往 nvm项目页面 寻找定制路径的方案 nvm 有两个版本，nvm-windows 和 nvm。 最近 nodejs.org 的 cdn 也很不错了，不设置 mirror 很多时候是能下载得动 nvm： 12345678910# install nvm, 安装后记得重启终端让环境变量生效curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.1/install.sh | bash# nvm 不支持配置 mirror，但提供了环境变量来影响配置export NVM_IOJS_ORG_MIRROR=https://npm.taobao.org/mirrors/iojsexport NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/node# 以下安装 lts 版本 node 命令nvm install --ltsnvm use --lts nvm-windows: 123456789REM nvm-windows 贴心的给我们提供了文档 https://github.com/coreybutler/nvm-windows#usagenvm node_mirror https://npm.taobao.org/mirrors/node/nvm npm_mirror https://npm.taobao.org/mirrors/npm/nvm list availableREM 安装版本需要自行填写nvm install %VERSION%nvm use %VERSION% npm12345678# 必备的、或许有用的、应该有用的，都在这了npm config set registry=https://registry.npm.taobao.org/npm config set electron-mirror=https://npm.taobao.org/mirrors/electron/npm config set phantomjs_cdnurl=https://npm.taobao.org/mirrors/phantomjs/npm config set chromedriver_cdnurl=http://npm.taobao.org/mirrors/chromedrivernpm config set sass-binary-site=https://npm.taobao.org/mirrors/node-sass/npm config set SELENIUM_CDNURL=http://npm.taobao.org/mirrorss/selenium/npm config set profiler_binary_host_mirror=http://npm.taobao.org/mirrors/node-inspector/ Yarn123456789yarn config set registry http://registry.npm.taobao.org# 以下未经测试yarn config set electron-mirror=https://npm.taobao.org/mirrors/electron/yarn config set phantomjs_cdnurl=https://npm.taobao.org/mirrors/phantomjs/yarn config set chromedriver_cdnurl=http://npm.taobao.org/mirrors/chromedriveryarn config set sass-binary-site=https://npm.taobao.org/mirrors/node-sass/yarn config set SELENIUM_CDNURL=http://npm.taobao.org/mirrorss/selenium/yarn config set profiler_binary_host_mirror=http://npm.taobao.org/mirrors/node-inspector/ Javamaven12345&lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://mirrors.huaweicloud.com/repository/maven/&lt;/url&gt;&lt;/mirror&gt; 或者使用这个 1curl -o ~/.m2/settings.xml https://mirrors.huaweicloud.com/v1/configurations/maven? 1curl -o %USERPROFILE%/.m2/settings.xml https://mirrors.huaweicloud.com/v1/configurations/maven? pythonpip(pypi)1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple","link":"/2020/02/id_3755372975/"},{"title":"电脑上不了网的排查思路","text":"最近总有连不上网瞎搞然后问我连不上网了怎么办(只说连不上，却不清楚哪里连不上，你就算说一句网页打不开了都行啊) 所以写下了这个排查思路 如果稍微懂一点命令行，知道 cmd 怎么打开怎么敲，可以直接去进阶版本，排查更快 基础版 是否连上了物理网络，就是网线、wifi 这都无法保证，你是怎么舔个脸说自己网不好使的呢 检查是否有 ip 地址 具体方法，拿手机自行百度，操作系统不同位置不同，懒得讲 如果是 wifi，用手机连上同一个网络试试，记得把手机流量开关给关上，不然会开着 wifi 却从流量上网，影响判断 如果手机不能用，那么问题就在于这个网本来就不能用，自己家的话，打电话给宽带公司让他们上门修吧 打开网页，输入 www.baidu.com 若无法访问，输入 http://123.207.151.189 (这是我的地址)，注意标点，只要看到 404 Site 123.20xxxxxxx就算成功 如果直接访问数字地址成功，但 www.baidu.com 失败，可能是 dns 服务配置有误，那么重启个电脑或者等上几分钟或许自己就会好。没好的话，可能真的是配置不对；如果自己不知道什么时候配置了这东西，怀疑电脑坏了吧 若无法访问，可能电脑出了问题，请思考是不是用了什么奇怪的软件 进阶版注意：该思路需要敲命令行，如果连 cmd 都不知道怎么打开，就参考上面的基础版本吧 思路如下： 保证物理连接 保证有正确的 ip 电脑到网关是通的 绕过 dns 环节，可访问纯数字地址 测试 dns 就这几个步骤，其中物理连接，自己看网卡状态好了 保证有正确的 ip cmd 输入 ipconfig，能看到类似于下文的内容，可能会有很多条，也可能名字和我对不上，地址和我对不上，那都不重要。 123456789ipconfig以太网适配器 以太网: 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : fe80::48c1:413e:ee4b:1b35%9 IPv4 地址 . . . . . . . . . . . . : 192.168.3.56 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : 192.168.3.1 电脑到网关是通的 上一步结果中，默认网关对应的地址，作为这步的参数 cmd 输入 ping 192.168.3.1，把 192.168.3.1 更换为自己的默认网关 正常结果如下： 123456789101112&gt;ping 192.168.3.1正在 Ping 192.168.3.1 具有 32 字节的数据:来自 192.168.3.1 的回复: 字节=32 时间&lt;1ms TTL=64来自 192.168.3.1 的回复: 字节=32 时间=1ms TTL=64来自 192.168.3.1 的回复: 字节=32 时间&lt;1ms TTL=64来自 192.168.3.1 的回复: 字节=32 时间&lt;1ms TTL=64192.168.3.1 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 0ms，最长 = 1ms，平均 = 0ms 如果长得不像(别问不像到什么程度，都是中文，一眼就能看出有问题来)，那么这一步骤失败，电脑可能出现网卡驱动问题，或者IP地址并不正确 不过这个不够准确，因为有可能路由器(网关)禁止了 ping 命令，所以无论怎样，都应当进行下一步 绕过 dns 环节，可访问纯数字地址 直接用浏览器打开 123.207.151.189，不报错就算成功 如果失败，证明网是断的。 网关能通，网却是断的，问题在上游，该找宽带报修就报修吧 测试 dns 直接访问 www.baidu.com，如果没通，证明 dns 出了问题 可以尝试更换 dns，但别忘了测试后换回来 更换 dns 方法，自行百度 建议 223.5.5.5 阿里 dns 也没问题的情况 那么，你到底是怎么得出网不好使的呢","link":"/2020/07/id_1816640273/"},{"title":"Java 获取客户端真实 IP","text":"一般来讲，获取客户端 ip 很容易。但是现在的部署结构，服务端都是在各层反向代理之后，直接获取的 ip 都是反向代理的 ip。 现在，主流的做法有两种 根正苗红的 RFC 7239 Forwarded2014年 IETF 组织提出了 [RFC 7239](https://tools.ietf.org/html/rfc7239) 解决这一问题。 但这玩意太新了，目前 Java 阵营，没几个支持的…… 这里有热心网友的统计https://c960657.github.io/forwarded.html 就说 spring 一家，除 webflux 天生支持外，基于 servlet 的全都不认这东西。也就是说，spring-mvc, springboot 等目前还不支持 不过有开源的 filter 提供了相应的支持代码，可以尝试一下，因为我没有测试过，这里并没有地址可贴，自行寻找。 大概看起来就是这样的Forwarded: for=192.0.2.60; proto=http; by=203.0.113.43 可以参考 Forwarded - HTTP | MDN 社区方案 X-Forwarded-*为了解决这个问题，社区推出了一个方案，将各层反向代理的 ip 都写在祖传属性 http.Header: X-Forwarded-* 属性中 因为 RFC 7239 推广程度还不够乐观，所以，现阶段靠谱点的做法还是用这祖传的东西 Java 端用起来也很方便，这里提供两个推荐方案 tomcat filter tomcat 提供了一个 RemoteIpFilter 可以支持 X-Forwarded-* 的请求头部，自动根据这个修改 ServletRequest 中 getRemoteAddr 方法返回值，只需要启用该 filter 即可实现 这个方法十分简单，spring boot / springMVC 均适用，强烈推荐。但局限于标准的 X-Forwarded-* 规则，所以有复杂需求的话，还是选择下面的方法吧 springboot + tomcat 适用 tomcat 在 springboot 中提供了以下配置，可以配置用于传输”x-forwarded”信息的headers名： server.tomcat.remote-ip-header=x-your-remote-ip-header server.tomcat.protocol-header=x-your-protocol-header 什么？你说你用 Jetty？那可以试试这个 ForwardedRequestCustomizer，效果更好。 什么？你说你用睾贵的 Undertow？自己找吧，这东西我么用过。","link":"/2020/02/id_883234523/"},{"title":"裸机运维(一)-远程服务器安装","text":"intro裸机运维系列1 文中提到的工具，在文末有下载地址 最近因为点特别情况，需要远程搞几台服务器 服务器有超微板子的工控机，有 dell r610 和同年代的 r410，反正都挺慢的 用 IPMI 远程安装系统，也算是裸机运维的第二步。你问第一步是啥？当然是给 IPMI 配地址了啊 prefirst机器不在本地，远程那边有一个 windows 10 来做工作环境，所以下文本地指代的都是这台 windows 10。 安装系统的过程，和自己插 U盘 安装完全一致，也就没什么多说的了 因为网段内，没有啥基础设施，机器也不多，所以 IPMI 手动改静态ip，省心 dell 可以直接在面板上按，超微工控就得进 bios 了，好在超微板子开机快，并不是太费劲。 (dell)的机器忘了拍照，感兴趣的自己去玩吧 dell 的 idrac，一个字，慢，哪方面都是 环境准备首先，IPMI，需要 java。 嗯……我这都是老机器，没有 web console 那种先进玩意 所以，先装一套 java。 尤其注意，oracle jdk 8。别装错了 javaws 在这里比较方便用，其他版本，虽然有不少也可以的，不过9之后的版本，安全设置位置不同，得自己找资料 如果你的机器不是那么野性，可以直接用 OpenWebStart ，可惜 r610 的 idrac 不改 Java 安全文件就起不来，我还是单独装了一套 jdk 安装系统粗野的手法直接在 ipmi kvm 中挂载 iso 即可，就像是自己插了个u盘上去 当然，这个方法，有个很傻逼的点，就是速度实在是，太慢啦！ 传输速度仅有 1m。一个 600m 的镜像，要 10 分钟才能启动。 ipxe 更加高端快速的手段本片文章主要记录的就是这部分 这里不是科普，不是技术探究，也不是什么尖端问题分析。只是记录自己的解法，当作备忘。 IPMI 直传，慢的原因在于 IPMI。就别想着什么优化了，我这俩机器拿线直接插上，也还是1m，可能这几个机器的 IPMI 就这么设计的吧 破局的方法是 PXE 网络引导，通过本地搭建 PXE 服务器做引导。解决 IPMI 速度过慢问题。 我没有测试原生 PXE 咋样，我嫌麻烦，用了比较成品的方案。 ipxe 可选使用 http 传输，速度嘛，打满了百兆(这几台机器 IPMI 都是百兆网卡) 我懒得去找台 linux 搭建 ipxe，所以偷懒用了 tiny pxe server。 界面十分简单。有需要详细教程的自行百度。因为我的网卡 pxe 都是跑在 legacy 引导下，所以没法上 uefi 我的应用场景很简单，拿 PXE 替代引导U盘 就行，把镜像放到指定位置，选好网卡，点击启动就行了。 程序自带 httpd:80，DHCP 所以当心当前 vlan 内有其他新设备上线，会被分配到 IP 的。 默认配置文件在 menu.ipex，需要自行改动，语法很简单，找使用了 sanboot 的项目，复制一份改一改就能引导 顺带一提，网吧的无盘系统，就是用 pxe 启动 iscsi 更自动化的竞品 netboot.xyz只是简单跑了一下，如果我要部署的是 ubuntu，或者 centos，我或许会用这个 当然，网速够快的话 QAdell r610 Connection Failed这个问题发生于 idrac 6, java 8+ 官方有过相应报告，有说法是换成 java 1.7 就好，不过我并没有现成的环境 原因似乎是 idrac6 默认使用的 tls 算法被标记为禁用，所以最后有两种解法 修改 jre 的文件，解除禁用 需要修改配置文件 本方法基于 oracle jdk 8，似乎哪个小版本都成 修改文件 {JRE_HOME}\\lib\\security\\java.security 直接将 jdk.tls.disabledAlgorithms 注释掉 123456789101112131415161718192021222324252627282930313233## Algorithm restrictions for Secure Socket Layer/Transport Layer Security# (SSL/TLS) processing## In some environments, certain algorithms or key lengths may be undesirable# when using SSL/TLS. This section describes the mechanism for disabling# algorithms during SSL/TLS security parameters negotiation, including# protocol version negotiation, cipher suites selection, peer authentication# and key exchange mechanisms.## Disabled algorithms will not be negotiated for SSL/TLS connections, even# if they are enabled explicitly in an application.## For PKI-based peer authentication and key exchange mechanisms, this list# of disabled algorithms will also be checked during certification path# building and validation, including algorithms used in certificates, as# well as revocation information such as CRLs and signed OCSP Responses.# This is in addition to the jdk.certpath.disabledAlgorithms property above.## See the specification of &quot;jdk.certpath.disabledAlgorithms&quot; for the# syntax of the disabled algorithm string.## Note: The algorithm restrictions do not apply to trust anchors or# self-signed certificates.## Note: This property is currently used by the JDK Reference implementation.# It is not guaranteed to be examined and used by other implementations.## Example:# jdk.tls.disabledAlgorithms=MD5, SSLv3, DSA, RSA keySize &lt; 2048#jdk.tls.disabledAlgorithms=SSLv3, RC4, DES, MD5withRSA, DH keySize &lt; 1024, \\# EC keySize &lt; 224, 3DES_EDE_CBC, anon, NULL, \\# include jdk.disabled.namedCurves 这个配置是禁止 tls 使用某种算法，注释掉是全部放行，有一定风险，不过 java 8 在我这并不是主用 也有一个说法，移除掉 SSLv3 和 RC4 就行，让两边使用这些算法 直接给 idrac 签个证书 这个方法是 dell community 中提供的方法，我没有尝试 一些傻逼的情况 dell r610 的 idrac 中，下载 jnlp 文件，后缀名会错，需要手动改…… dell r610 的 jnlp 默认文件名极长，用 OpenWebStart 打开会报错。手动删掉一大段就好了。 超微的ipmi，kvm中 默认 F2 是退出。esxi 界面上，F2 是设置……就很尴尬，需要在 Options 中改键 超微的ipmi，kvm中 esc 也有很恶心的情况，记得改配置的时候，看好了提示框是啥我不小心重启了两次……好在重启很快 超微提供了 IPMIView20，好歹能用，但是吧，都 2020 年了，就不能适配一下高DPI吗，我这高分屏看着好难受啊(虽然这锅可能要丢给Java) 这个 IPMIView 中，不晓得是不是带的 jdk 版本有毛病，kvm 中没法挂载 iso，最后还是得靠 OpenWebStart OpenWebStart，自带了下载 jdk 的功能，可下载的版本实在太新，面对旧设备(dell r610)，居然没法握手。还得手动改 jdk，再靠修改 jdk 中允许使用的安全算法，避让这个东西。傻逼老 dell 剩下的不太想得起来，再说了 Other文中的工具下载地址 OpenWebStart IPMIView pxesrv pxesrv作者博客 官方下载地址(很慢) 我的镜像(08/01/2020)","link":"/2020/11/id_2184768189/"},{"title":"记录DHCP-clientid导致IP冲突","text":"本次问题基于 ubuntu 1804, centos用户不要对坐(号)入号(座) 最近弄了一台物理服务器，复制了几个 ubuntu 1804，但出了一个神奇问题，这几台机器无一例外，dhcp获取的都是同一个ip 百思不得其解的问题，明明 mac 地址不同，为何会出这种事情 然后开始了排查历程 先做几个备忘： ubuntu 1804，废弃了 ifupdown，改用 netplan 配置网络，学习成本不高，配置文件在 /etc/netplan/*.yaml，语法比较简单 可能用到的命令行 netplan ip leases &lt;device&gt; 查看网卡信息 netplan try 执行配置 排查过程中，做了以下尝试： 尝试了重启网卡 重启网络服务 重启机器 dhclient 重新分配 ip 无果 重启网卡时，还遇到了 ifdown 不存在，原来是被废弃了，用 netplan 替代 但在 netplan ip leases 中，发现了一个参数， CLIENTID，这几台虚机的id是完全一致的 我的直觉告诉我，问题就在这里 翻到了靠谱的 RFC-4361 Node-specific Client Identifiers for Dynamic Host Configuration Protocol Version Four (DHCPv4) 规范 知其所以然，还是不知道咋解决…… netplan 提供了这个参数 dhcp-identifier 提供了可以用 mac 当作 dhcp clientid 的配置，尝试一番，可行 剩下的基础知识，有空再补充 2020-05-18 更新 dhcp clientid 的默认值会根据 machine id 变更，克隆出的几台机器完全一致，所以这里才是真正的祸根 12# 查看 machine-idcat /etc/machine-id 可以使用 dbus-uuidgen 来重新生成一个 machine-id 12sudo rm -f /etc/machine-idsudo dbus-uuidgen --ensure=/etc/machine-id https://unix.stackexchange.com/questions/402999/is-it-ok-to-change-etc-machine-id 然后重新使用 netplan apply 获取ip，收工。 然后，写了个一次性脚本来做这个工作。方式多的很，自行研究了","link":"/2020/05/id_661479498/"},{"title":"前端项目迁移至 nuxt.js","text":"文章书写于 2019-09-06，改造是8月中旬，使用的 nuxt.js 版本为 2.8.1，后升级到2.9.0，文中可能包含两个版本的内容，区别不是太大，关于版本差距详见nuxt/nuxt.js 目前项有 SEO 的需求，而前端是纯正的 SPA 应用，国内的搜索引擎目前对这些东西都没有办法，所以考虑启用 SSR 服务端渲染方案 官方提供了三种可行方案 vue-server-renderer 服务端方案 prerender-spa-plugin webpack预渲染插件 nuxt.js 如果页面较少并且固定，那还是推荐使用预渲染方案，不过我们有详情页面需要渲染，所以这个方案无法实现，而 vue-server-renderer 因为要搭建太多内容，我们追求快速落地，所以该方案 pass。 我们最终选用了 nuxt.js，本文记录整个迁移过程和遇到的坑 intro目前项目结构为 webpack, typescript, sass vue, vuex, vue-router element-ui axios baidu-map 没有 jquery，手脚架为 vue-cli3 的官方手脚架(用 vue-cli-service 启动的)。 项目中大部分数据都放进了 vuex，包括登录，vuex 的数据自动保存到 localStorage 中 注意，本文的大部分说法，都是基于 typeScript，有些说法可能在 js 环境不适用，请自行测试 还要说一句，typeScript 搞这东西，真不太好用 nuxt.js看官网吧 加一些我自己的补充 nuxt 的工作模式，按照我自己的话来说就是混合渲染，只有页面在首次加载时会触发服务端渲染，前端的交互操作依然遵照 SPA 的方式。 这个逻辑必须要理解，不然会遇到各种数据不加载、undefined、页面多次渲染等等一系列问题。 对新手说的话，就是浏览器刷新、地址栏敲回车。 然后，nuxt 的 asyncData 和 fetch 两部分，可能在服务端执行可能在客户端执行，但一定只执行一次，所以 asyncData 和 fetch 必须要设计成服务端和客户端都可以执行的结构。 生命周期nuxt.js 的生命周期 vue.js 的生命周期 其中，nuxt.js 的 Render 部分，后续会接上 vue.js 的生命周期，包含 beforeCreate 和 created，而浏览器端也会再执行 beforeCreate 和 created 两个钩子，这是服务端渲染的性质。 框架搭建不建议自行添加依赖，最好是直接官方手脚架生成，然后将现有项目迁移上去 原有项目的目录结构如下 12345678910111213141516171819202122232425├─public├─scripts├─src│ ├─api│ ├─assets│ │ ├─font│ │ ├─images│ │ └─scss│ ├─components│ ├─config│ ├─router│ ├─store│ │ └─module│ ├─types│ │ ├─components│ │ └─views│ ├─utils│ ├─views│ │ └─index│ ├─App.vue│ └─main.ts├─tslint.json├─tsconfig.json├─vue.config.js├─package.json 因为 nuxt.js 的目录结构有规范，可以用来实现很多功能，所以基本上遵照了目录结构新的目录结构为 123456789101112131415161718192021222324252627282930├─.nuxt├─server│ ├─middleware| └─index.js├─src│ ├─api│ ├─assets│ │ ├─font│ │ ├─images│ │ └─scss│ ├─components│ ├─config│ ├─layouts│ ├─middleware│ ├─pages│ │ ├─index│ │ └─index.vue│ ├─plugins│ ├─static│ ├─store│ ├─types│ │ ├─components│ │ │ └─userCenter│ │ └─views│ └─utils├─tslint.json├─tsconfig.json├─vue.config.js├─package.json├─nuxt.config.js 这样调整尽量符合原有结构，为了这个目录结构还需要配置几个属性 nuxt.config.js 12345module.exports = { mode: 'universal', srcDir: 'src', // 将源码路径指向 src，默认同 rootDir 为项目根目录 // other...} nuxt.js 是自动生成路由的，所以取消了 router 目录，如果要干预可以在 nuxt.config.js 手动注入额外部分，但自动部分还是会工作；如果要对路由进行影响可以增加 middleware，在路由响应时改变上下文或者改变路由目的地；对于动态菜单这种需求，那种后管平台没有 SSR 的必要，建议放弃 原有项目的 views 更名为 page，因为自动生成路由，所以目录结构要按照 nuxt.js 的规则来，详见 迁移指南-pages assert 和 static 都是放置静态资源的地方，区别在于 assert 通过 loader 加载，可以解析 sass 等格式，而 static 为纯静态资源 components 为组件，这部分不会受到 nuxt.js 加强，也就是没有 nuxt.js 的生命周期钩子。注意该部分打包时会全部封进 app.js，如果组件是某个页面专用，就请移动到 pages 中，不要放在这里 layouts 作为布局，所有渲染的页面都要有一个对应布局，默认的布局名称为 default.vue，就是渲染模板，这里可以一定程度代替 App.vue 和 main.ts middleware 放置路由中间件，中间的 js 文件会自动以文件名为 name 注册进 nuxt.js，在 nuxt.config.js、layouts、pages 中可以使用中间件。layouts、pages 中，使用属性 middleware: {{name}} 即可；nuxt.config.js 中按照这个格式注入 12345module.exports = { router: { middleware: 'stats' }} plugins 文件夹内的文件会做为定制原型链的插件。因为渲染机制问题，Vue 的实例初始化没有暴露出来，nuxt 提供的方案是使用 plugins。但是有很多插件注入后会出现问题影响 nuxt 正常工作，谨慎使用 store 为 vuex 的目录，nuxt 会自动生成 vuex 树，只要将 store 文件直接放入 store 目录就行，nuxt 会根据文件名生成 modules 迁移指南迁移方案选择新搭建框架，再将业务代码迁移上去。 第一步迁移的是基础工具和接口代码。 然后迁入基础结构，首先处理 App.vue 和 main.ts App.vue 对应到 layouts/default.vue 中，根据 nuxt.js 的结构做一些替换。概念不同，但结果一致。日后还是更建议将 header、footer 分发到 layouts 中，可以更好的规划布局和统一布局 整体的代码执行顺序如下，自行对照到生命周期中： nuxt.js =&gt; plugins =&gt; router =&gt; router-middleware =&gt; layout =&gt; asyncData/fetch =&gt; create storestore 会自动按照名字分 modules，所以要确保 store 文件的命名和以前引用的模块名一致，不然就要大片的改动代码 服务端渲染需要 state部分返回一个无参方法，这里用的 ES6 语法 1234const state = () =&gt; ({ recentContactList: [], chatRecordList: []}) 根据服务端渲染的逻辑，每次服务端渲染，vuex 都会重新初始化，vuex 的初始化在服务端，时机很早(应该是nuxtServletInit就有)，也就是说没有以前的数据。针对这一点有一些解决方案，但强烈不推荐将用户端的 vuex 同步到服务端这一做法，看似很美好但同步方面坑相当多。 对于服务端没有 vuex 数据的问题，我建议针对性的处理，如用户 token、用户关键信息 可存放到 cookie 中，一些整个项目随处都要用的数据也可以存放到 cookie 中。但注意容量，cookie 的空间很宝贵 对于 vuex 的一些初始化动作，举个例子，用户信息存放在 vuex 中，业务方都是在 vuex 中获取，我们可以在 middleware 中将用户信息从 cookie 中读出，存放到 vuex 中。 目前的前端有 localStorage 来保存 vuex 数据，但是要考虑数据合并造成的冲突，因为服务端渲染会将 服务端vuex 中的数据带到客户端，客户端会使用这些数据做初始化，确切的说是 初始化 =&gt; 合并服务端vuex，如果客户端从 localStorage 做了本地化，切记在合并数据时注意不要将服务端某些关键数据覆盖掉。 对于那些过度依赖 vuex 的功能，比如列表翻页的页码存放到 vuex，我建议着手拆除这类业务对 vuex 的依赖，vuex 不是这样的工具 pagespages 为页面入口文件夹 服务端渲染的改造基本都在这里 根据路由生成规则，pages/index.vue 是首页入口 layouts 中的文件代替了 App.vue。 其中 layouts/error.vue 文件比较特别，这个是错误页面，后端渲染错误、后端路由错误，都会跳转至此。 Routernuxt 会根据放入 pages 中的 文件夹/文件 来生成路由Router 规则为： // 若 vue 文件为 index.vue，则不会生成文件名层级 在 Nuxt.js 里面定义带参数的动态路由，需要创建对应的以下划线作为前缀的 Vue 文件 或 目录。 以下官网样例： e.g. 假设目录结构为 12345678910pages/--| about/-----| index.vue-----| one.vue--| users-----| _id.vue--| _slug-----| comments.vue-----| index.vue--| index.vue 生成的路由为 1234567891011121314151617181920212223242526272829303132routes: [ { name: 'index', path: '/', component: 'pages/index.vue' }, { name: 'about', path: '/about', component: 'pages/about/index.vue' }, { name: 'about-one', path: '/about/one', component: 'pages/about/one.vue' }, { name: 'users-id', path: '/users/:id?', component: 'pages/users/_id.vue' }, { name: 'slug', path: '/:slug', component: 'pages/_slug/index.vue' }, { name: 'slug-comments', path: '/:slug/comments', component: 'pages/_slug/comments.vue' }] 生命周期钩子nuxt 的 SSR 可以说成是混合渲染，首次加载时由服务端渲染，其余的时间点都和 SPA 一致。 为了让服务端渲染时能将数据渲染到 html 中，就需要在 render 前将数据填充到应该放置的地方(data 或者 vuex) 再强调一次，vuex 在初始化时，是空的。 整体的流程可以参照生命周期的图 asyncData 和 fetch 两个步骤可以对数据进行影响，fetch 设计的功能就是填充 vuex。asyncData 还额外的有一个特点，就是该步骤的返回值会合并到该页面的 data 属性中(ts语法可能不太明显，js 语法的 data 就比较容易理解了)。 这样就可以通过 asyncData 和 fetch 控制服务端渲染时，数据的范围 注意，asyncData 早于 render，所以这时还没有 this 使用，也就是和 vue 实例挂钩的内容都用不了。虽然 context 中提供了一个叫 app 的实例，但那个是 nuxt 的实例，不是当前页面的 还要注意，asyncData 和 fetch 都有可能在客户端执行，两者在整个流程中都只会执行一次。但是 create 生命周期在两端各会执行一次，如果可能的话，可以将 created 中的代码移植到 mounted 中。若还是需要使用 created(毕竟mounted慢一步)，可以选择使用以下代码做判断 123if (process.client) { // } ts 的写法与 js 不同，ts 中，asyncData 和 fetch 需要写在 @Components 中，如下所示，其中 asyncData 和 fetch 的入参 context 中包含的内容参见 Context 12345678910111213141516171819@Component({ components: { Footer, QuickBar, NoData }, async asyncData ({ params, store, error }) { if(params.id) { let a = await store.dispatch('AModules/ACTION_A', { id: params.id, }).catch((err) =&gt; { error({ statusCode: 500, message: '数据异常' }) }) return a } }, async fetch() { await }})export default class SecondDetails extends Vue { // other} meta 标签nuxt 内部引入了 vue-meta 插件来做 meta，除了默认的命名外，使用方法完全相同，和 vuex 一样需要返回的是一个方法。具体参见 (Vue Meta)[https://vue-meta.nuxtjs.org/guide/metainfo.html]以下官网样例: 12345678910@Component({ head () { return { title: `Page 1 (${this.name}-side)`, meta: [ { hid: 'description', name: 'description', content: &quot;Page 1 description&quot; } ], } }} head 的执行时机为 render，这时是可以使用 this 的 keep-alive先说一下，nuxt 是有 keep-alive 的，layout.vue 的 template 部分如下： 123456&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;Login v-show=&quot;isLoginShow&quot; @close=&quot;onLogin(false)&quot;&gt;&lt;/Login&gt; &lt;nuxt keep-alive/&gt; &lt;/div&gt;&lt;/template&gt; 这一点不得不埋怨一下官方手册，好多东西真的是找不到，还是翻阅 changelog 和 issue 才得到的解决方案 调试服务端调试分为两部分，log 和 debug log 可以直接在控制台看到。nuxt 2.9.0 以后新增了 ssrLog 功能，可以将服务端的 log 打印到浏览器的 console 中 debug 部分，这部分有点玄学，因为有时候代码 debugger 抓不住，我也说不太清楚 方案为，借助 node 的参数 --inspect 将实例的 debug 功能打开，然后使用 chrome 浏览器进行调试，本机环境只要点击 F12 就能在 Elements 选项卡左边看到 node 的图标 成功的话，在启动时就可以看到日志 12Debugger listening on ws://127.0.0.1:9229/61388480-18e2-4f4d-8373-f7b9909d8011For help, see: https://nodejs.org/en/docs/inspector 一些使用技巧js-cookie 提供一个修改过的 js-cookie，可以在服务端渲染时提供相同的 api，cookie 为空时会默认读取 document https://gist.github.com/ZzMark/d93bbcbbf3b6e763062c977c269edcbf 在 asyncData 中的用法样例如下 123456789asyncData({req}) { let cookie if(process.server) { cookie = req.headers.cookie } const userInfo = Cookies.getJSON('userInfo', cookie) || {} // ...} 按需渲染 有的地方没有必要让服务端渲染，SSR 针对性的将有必要的东西放到服务端即可。不过话是这么说，实际上反而是将不必要的去掉 不需要服务端渲染的地方，用 嵌套起来。 但要注意，如果不想让某个组件加载，需要在引用组件的地方用 no-ssr，不能在组件上。 典型的场景是，某个组件需要数据，没有数据导致了服务端渲染时出现了 undefined，直接用 no-ssr 将那一块套起来是没有用的 对了，no-ssr 在 nuxt3 就会被移除，尽快迁移到 吧 全局加载scss SPA 场景下，直接 import 即可，但这里不行 可以使用 module: @nuxtjs/style-resources 在 nuxt.config.js 中配置 123456789module.exports = { modules: [ '@nuxtjs/style-resources', ], styleResources: { scss: ['./src/assets/scss/common.scss', './src/assets/scss/font.scss'] }, // ...} 打包、优化开发环境，建议使用 nuxt 来启动，生产环境更换为 express，方便在 express 中增加一些定制信息（我们在 express 中做了压缩相关的内容，这个下面会讲）。 附上我的启动指令 1234&quot;dev&quot;: &quot;cross-env NODE_ENV=development DEBUG=nuxt:* node node_modules/nuxt/bin/nuxt&quot;,&quot;debug&quot;: &quot;cross-env NODE_ENV=development DEBUG=nuxt:* node --inspect node_modules/nuxt/bin/nuxt&quot;,&quot;build&quot;: &quot;nuxt build --profile&quot;,&quot;start&quot;: &quot;cross-env NODE_ENV=production node server/index.js&quot;, 项目精简这个问题，仁者见仁。 大部分会遇到的应该都是按需加载，这个要挨个去试。 build 时候可以增加参数来触发 nuxt 提供的 analyze 功能(其实就是 webpack-bundle-analyzer，用过 webpack 的人都知道) 用我的命令就是npm run build -- -a 剩下的看着来吧 静态压缩目前项目短期内没有使用 CDN 的打算，所以首屏加载速度的一个大头就要靠自己了。 直接使用 nuxt 的 render.compressor 只能做到首屏的 html 压缩，其余的 js 都是动态压缩，消耗过多的资源，所以打算像 SPA 那样，部署时直接放入 .gz 和 .br 文件，节约算力。但 nuxt 并没有这方面支持，所以只得靠 express 来直接返回资源。 整个改动分为两部分。1. build 时生成静态压缩文件; 2. 让 express 返回静态压缩文件 第一部分我编写了一个 middleware，代码贴在这里。实际上逻辑很简单，就是调用了 compression-webpack-plugin 生成 gzip，brotli-webpack-plugin 生成 brotli。 npm install -D brotli-webpack-plugin compression-webpack-plugin /server/compressModule.js 1234567891011121314151617181920212223242526272829303132333435let CompressionPlugin;let BrotliPlugin;const gzip = { test: /\\.(js|css|html|svg)$/};function getPlugin() { if(!CompressionPlugin) { CompressionPlugin = require(&quot;compression-webpack-plugin&quot;); } if(!BrotliPlugin) { BrotliPlugin = require(&quot;brotli-webpack-plugin&quot;); }}function compressionModule() { this.extendBuild((config, { isDev, isServer}) =&gt; { if (isDev || isServer) { return; } getPlugin() const options = this.options[&quot;nuxt-compress&quot;]; const gzipConfig = options ? { ...gzip, ...options.gzip } : gzip; const brotliConfig = options &amp;&amp; options.brotli ? options.brotli : {}; config.plugins.push( new CompressionPlugin(gzipConfig), new BrotliPlugin(brotliConfig) ); });}module.exports = compressionModule; 然后在 nuxt.config.js 中添加以下配置 123456module.exports = { // version &lt; 2.9.0 使用 devModules 替换 buildModules buildModules: [ '~~/server/compressModule', ],} 第二部分要让 express 读取静态压缩文件，借助了 express-static-gzip 这个中间件。这个中间件做了比较完善的处理，放心使用 在 express 入口，注册这个中间件 12345// 加载 static gzip br 并优先提供 brotli 压缩app.use(&quot;/_nuxt/&quot;, expressStaticGzip('./.nuxt/dist/client', { enableBrotli: true, orderPreference: ['br']})); 该配置基于默认情况，build 后访问的 js 路径为 example.com/_nuxt/xxxxxxxxxxxxxxx.js css 分离nuxt 提供了配置，直接使用即可实现大概的效果 build.extractCSS = true 如果要精确来，就自行研究吧，反正这个是实现我们想要的样子了 其他 nuxt.js 的坑 layout 如果在 下方有组件，会出现两次渲染的问题，这个问题我也解释不了，我是直接绕开了这个。有发生相同情况的小伙伴就去提 issue 吧 nuxt.js 选用了 axios，依赖为 @nuxtjs/axios，官网说不需要自行再引入 axios，但我这里不引入什么都干不了……nuxt.config.js 中要加入 modules 配置，手脚架已经给出了配置我们的业务会通过API封装执行 http，所以不需要进一步处理 服务端的 axios 不会自动携带 Cookie。如果想要优雅的解决，那就在 axios 封装那里新增一个接口来注入 Cookie，然后靠 router-middleware 从 context.headers.cookie 获取并注入 vuex 在服务端初始化，然后将数据递交给前端，不清楚客户端初始化时会不会再初始化插件 引入许多代码都会出现 unexpected identifier，可以在调用栈中看到是哪个 loader 加载哪个文件时发生的问题，调用栈可以看报错时的网页。但并不好解决，一般时候都是因为组件注册，引入时调用了某些代码，目前的解法都是改为直接引用组件，让整条链路避开 Vue.use 和 Vue.component。 凡是动用 window 或 document 以及下设对象的代码，都要避免让服务端执行。 Vue.use() 有不少组件无法引入，解决方案为局部引入。但也有组件局部引入就无法工作，这时候可能就要全局引入。 目前有一个最坑的东西，not matching，服务端渲染结果与浏览器渲染结果不匹配。开发环境会导致浏览器抛弃冲突的标签重新再渲染一次，并抛出警告；生产环境不会有处理。官方讲最常见的是 table 中的 tbody，实际场景中，服务端 render 和客户端 render 不匹配就会出现这个，比如客户端因为数据不同重新渲染的结果不一致这个问题尽量避免，因为可能会出现因数据异常导致页面直接卡住(常见于 v-if 使用不当) 如果出现这个警告WARN: Please use build.postcss in your nuxt.config.js instead of an external config file. Support for such files will be removed in Nuxt 3 as they remove all defaults set by Nuxt and can cause severe problems with features like alias resolving inside your CSS. 实际上是很小的事，就是告诉你 postcss 要配置到 nuxt.config.js 中了，把 postcss 的配置文件中所有内容配置到 build.postcss 中即可。 后记关于这次迁移，满网搜索都是 nuxt 的 demo，就没有一个拿出点干货。 现在做技术，实在是有点太浮躁了，自以为写个 demo 就是会了一切。 其实整个迁移过程中，遇到的坑还有很多，但是有许多都是前端代码写的不够严谨，用法不规范导致，也不好意思拿出来。看到这篇文章的有缘人如果遇到什么问题无法解决，欢迎叨扰，或多或少我会帮得到您。","link":"/2020/02/id_3995044274/"},{"title":"Windows-系统规划、系统重装、系统优化","text":".content h2, .content h3, .content h4, .content h5 { color: #3273dc } 本文写自 2020-12-28 日，后半的内容都是在讲故事，重点都在前面 里面的图不是同一台电脑截出来的，不要挑刺 文字极多，我不太会做教程那种啰嗦东西，随便看吧 想到什么，我会慢慢往上更新 如今已经 2020 年了，坚持 xp 天下第一的，建议你去看看医生，让医生纠正一下你的 xp 系统 坚持 win7 天下第一的，如果能说出三个你日常使用下 win7 能做，win10 不能做的东西，那么只有两种情况 你的使用场景真的离不开 win7 你对系统的理解已经超越了我 以上两种，我都建议右上角关闭这个页面，不要浪费彼此的时间 以下内容，全都是基于 GPT分区 UEFI引导 windows 10 非LSTC版本，如果你不知道其中的是啥，可以无视，确保你的电脑是2012年(intel 初代i3/i5/i7, amd AM3插槽)后出产的型号就行 before 下文中出现的 C 盘，一律是系统盘的意思，怕有些人脑子转不过来 下文提到的 chrome，要么指代 Google Chrome 浏览器，要么指代 开源的 Chromium 内核，因为很多情况把 Chromium 内核叫成 chrome 内核也没什么问题，所以自行判断 辟谣 如今互联网十分发达，获取知识的成本也变得低廉。 但验证言论的成本越发变高，所以谣言总使比真话传得更快更广，更深得人心 每次看到网上传播的那些个谣言，总让人想到这句话 您还在用番茄花园吗，2020年了，不是2002年 让我们辟几个谣，贴上了目前能想到的几点。 以下几点，都是错的 软件不能装 C 盘，系统会变慢 软件装在哪里，速度都是一样的，速度不一样，只可能是你的硬盘有问题 软件装 C 盘太占地方，C 盘空间宝贵 用得多的人都知道，真正占地方的东西，都是些用户数据、缓存、临时文件，就算安装到其他盘，该占 C 盘的，还是占 C 盘 装系统时候，要分 CDEF 四个区，系统，软件，游戏，文档要分开放，玩游戏把硬盘弄坏了另外两个分区也不会受损 真要是硬盘弄坏了，只可能整个硬盘都挂掉，管你什么CDEFG分区都会死 不装杀毒软件，就该中病毒了；不装安全软件，就不安全了 不安装杀毒软件，确实风险挺大，但现在 win10 送的杀毒很猛，完全不用操心。 当然，防君子不防小人，你直接给了某个恶意软件超高的权限，还是会死 就算防了小人，也防不住手欠的，你自己关掉了各种更新，遇到漏洞入侵然后说不安全，我该说些什么 你这 Chrome 是美国的，不安全，咱们中国人得用中国的产品 国产……十年前国产车还是低端的代名词。国产浏览器，内核都是 chrome 的，美国心，只是有一个国产皮肤罢了 = 某60安全浏览器，把本应有的功能包装成会员专享，实在是软件工程的典范 = 18年国产自主研发，红芯浏览器，被爆出 chrome 换皮 = [自主研发一款浏览器内核的难度到底有多大？ - 罗志宇的回答 - 知乎] 自动更新总是让我电脑关不了机/总使提示我重启/更新后游戏就没法玩了/每次都更新失败，开着也没用 面对这种人，只能说微软实在太好心了，老掉牙的危险版本依然能让你用， 你看看 iOS，看看 Mac X OS，强制更新，不更新用个鸡儿，新软件全都不让安装 您信任那些安全软件的漏洞修复，却不信任最了解这系统的人给你提供的安全更新， 如果您对操作系统的理解远超微软，您可以给微软发个邮件，探讨一下系统更新应不应该从 windows 去掉 系统规划对于系统的规划，主要还是磁盘分区的规划，文件方面的规划，和系统优化方面的内容 系统优化，先讲讲我对优化这个行为的看法。 如今个人电脑的性能十分足够，现在的 windows，也没什么值得优化的点了 所以我个人是拒绝任何无脑优化的 当然，针对性的，比如说怎么跑满 100g 网卡，怎么驱动 RDMA，怎么插 4 块 nvme 固态还能跑起来 但是这些，大家应该都听不懂，说了也没啥意思 分区规划 我个人是不太喜欢分区的，反正分了区，也不会让文件变整洁，还要去区分哪个分区怎么用，想想就头疼。 但我个人还是拒绝单分区的，推荐将操作系统分离开来。这样重装系统时，可以减少备份的考虑，反正重装了系统，软件也是要重装的，自己的文件绕开C盘就好了 思路很明确， 100g~200g 系统分区，有空间就大点给着 固态有剩余，分配个固态的分区 剩下的一个分区一块盘 接下来都是个人见解，大体上区分成了几种情况，思路都是一致的 128g 固态 就这么点地方，您还是别瞎折腾了 128g/256g 固态 + 机械硬盘 这种场景我的分法是，C(128g 固态), D(机械) 512g/1t/2t固态 + 机械硬盘 C(128g 固态), D(剩余的固态), E(机械) 多块固态 方案1：适合大众。系统盘给操作系统上100~200G，剩下的分给一个分区，其他固态每个固态一个分区 方案2：跨区卷走起，当然，别存重要资料，小心集体爆炸 说说理由，其实上面都已经说过了 单纯的 win10 操作系统大概给 100g 以上就差不多够用，也得看软件和其他的数据文件占用多少。虽然经常看到C盘占用率到80%，不过无所谓，煮不在乎。软件多的话就多给一些 许多软件重装系统也必须重装，所以没必要非得绕开C盘 当然，绿色软件可以放到D盘，或者软件十分的多，不想占用宝贵的固态空间，也可以换到其他磁盘上 我的文档、下载、桌面，记得迁移到非C盘（后面有图） 文件规划 你们奉为设计的苹果，mac x os，并不存在 CDEF 磁盘分区 当然，苹果也没打算让一般用户在机器上安装多块硬盘 磁盘分区规划中已经提到的一点，软件放哪里无所谓，自己用户文件不要乱丢就好。 如果为了重装系统考虑，把不可再生的用户数据(比如自己做的ppt、照片、word等等)，移出 C 盘 我个人有整理文件的习惯，自己的文件位置都放的比较规整。 对于软件产生的文件，我倾向于默认位置，减少各种配置时要考虑的情况，出了问题可参考的内容也多 比如 maven 的仓库，默认就是 ~/.m2 ，配置文件就在这里qq 的聊天记录，默认放到 文档 中，因为 文档 已经移动到其他分区，也不会无限占用 C 盘空间，重装恢复难度为0软件安装路径，基本都是默认位置，有一些很大的、跟系统无关的，可能会修改个盘符 从 c:\\Program Files(x86)\\xxxxx 改成 d:\\Program Files\\xxxxx 抹掉 (x86) 这烦人字样，反正 windows 10 没啥必要区分 32位 还是 64位 当然，一些绿色软件，也会放到这里软件的安装包、或者自己的一些免安装小工具，那就指不定在哪了 关于整理文件，分享我自己的整理习惯 软件安装到 Program Files 用户文件直接迁移到 Users/xxxxxx，保持原有目录结构，就是简单换了个分区 干活的东西(可能不止一个种类，所以每个种类建议分离开)，找个地方集中放好 平常写的工作代码，都在 workspace/{项目名称}/{工程名称} github 或者一些个人积累代码，都在 github/{项目名称}/{工程名称} 视频处理工程(偶尔还会帮家里人剪个视频)，cut/{日期}/{工程名称} 文档类的，code/{类别}/{啥项目} 游戏，Games/{游戏名}，steam：Games/Steam/SteamLibrary，steam本体在c盘默认位置 照片、截图之类的 照片/手机照片/{手机型号}/DCIM 型号不同，文件名规则有可能不同。自增的id也可能冲突，所以每个手机单独存放。现在靠nas同步，不用担心同一个手机拍出相同的id了 照片/手机照片/{日期}/DCIM 没有nas的时候，手动复制，按日期搞就行，冲突自己有办法解决 照片/{相机型号}/{日期}/DCIM 以前还有相机用的时候，也存了一些这样的东西 音乐，迫于网易云全灰，我对云产品的信任真是一天比一天差。所以音频文件都是本地化的 music/cd/{歌手-专辑名}/xxxxx music/CloudMusic/{歌手}/{专辑} 下载的电影、视频、大压缩包 下载/{下载软件} 按软件分开管理，每个下载软件下的东西倾向不同， 系统相关 顺便，送各位一个工具 SpaceSniffer, 可以查看是哪个文件夹占用了您的宝贵硬盘空间 官网是意大利的，若下载不动，这里有下载好的文件我转存的/SpaceSniffer Windows 推荐配置我个人反感魔改系统，所以，这些修改都是遵循 Windows 提供的选项，没有危险操作 按照推荐程度，从上到下 把 我的文档、桌面、默认下载文件夹，都移动到其他分区上 这样可以将用户常用的位置都迁移到其他地方。不要让 qq 微信 打爆系统盘 打开 计算机(我的电脑)，在左侧找到桌面、文档、下载 等等想要迁移的 点击右键 - 属性 - 位置选项卡，将路径调整好，我个人倾向于维持原有文件夹名称，迁移到d盘。 确定即可，会提示是否移动文件 over 对于文件管理器，做一些配置。在文件夹选项中 防止最低级的病毒，以及恶意软件 显示隐藏文件， 隐藏系统文件(推荐) 显示文件的扩展名 隐藏文件夹合并通知 使用平铺这种布局，更容易一眼找到想要的文件。 还能看到一点缩略图，各方面都很均衡 我个人是不喜欢 windows vista 之后将列表设置为默认的 文件管理器上方 - 查看 - 平铺 文件管理器上方 - 查看 - 选项 - 查看选项卡 - 应用到文件夹，可以将当前文件夹的布局应用到所有同类文件夹 合并任务栏，默认情况下会始终合并任务栏，很不直观，个人更倾向于使用 当任务栏已满 这种，能让打开的东西都显示出来。 具体配置为，任务栏点击右键 - 任务栏设置 重装系统对于磁盘规划，之前也说过，用户数据(文档、下载、桌面) 都不在C盘种，所以我的电脑可以直接抹掉C盘重装系统，丝毫不用犹豫丢了重要文件 关于安装系统，自从 windows 10 1511 版本以后，MSDN的 iso 内核心的wim文件也超过了 4g，没法直接写iso或者找个u盘随便装，很是麻烦。 但，微软爸爸提供了更加方便的操作，官方工具，插上u盘直接制作安装盘，一键操作，长手就能用，只需要U盘大小大于8G小于32G(大于32g也有办法，只不过略微麻烦，小白直接无脑16g就好了) 下载 Windows 10 安装过程全中文，网页下边还提供了教程，不傻就能看懂。 不过还是说几句， 新机器安装系统时，建议安装阶段只给一个系统分区，避免不小心把系统装歪了地方 老机器重装系统时，用磁盘容量来确认是哪个分区，因为那个界面并没有 CDEFG 之类 闲谈无聊的过去 文章末尾，其实没什么用，讲讲故事了 故事中的那些傻子，肯定不是我。 我对于装系统这项技能的掌握很早，05年跟着电脑店的师傅学习过，07年自我尝试，09年后半就已经开始用上win7了，那时候还叫开发者预览版（?） 无师自通，师从外行，都是让人绕弯子的东西，但绕过的弯子，也让我理解了很多基础的东西，虽然现在眼界专业了，看着就跟玩笑一样 C盘？其他的盘？有什么区别以前玩多系统的时候，曾经做过操作系统在 F 盘的情况 当时身边的人很诧异，就问我，你这C盘咋没了呢 当时的情况是这样 分区1 win7(C) 分区4 win8(F) 切换系统时，将另一个系统的分区隐藏掉。也就只有 D E F 然后系统 logo 标记在了 F 上 这是个认知错误，并没有规定系统只能安装到 C，也并没有规定过 C 一定要存在 当然，这之后，我把 F 改成了 C，情况更有趣了 分区1 win7(C) 分区2 (D) 分区3 (E) 分区4 win8(C) 切换系统时，将另一个系统的分区隐藏掉 有很多人认为，CDEF 就是按照顺序排下来的。实际上，这也只是打了个标签而已，顺序都是随意的 嗯，当时也是震惊了很多身边半懂不懂的人 传统引导 - UEFI 过渡 时期的混沌距今最近的混沌时期，就是 传统引导 - UEFI 过渡的那个时期了 这个过渡期本应是 windows 7 的那个时代，也就是 10 11 12年，在微软的 vista 暴死之后 但那之后，win7 接手，这个系统过于成功，让那个过渡期并没有什么犹豫，多数人都是选择放弃 UEFI 引导的 所以这个过渡期被顺延到了 win8 的时代 首先，win7 可以在 CSM 技术加持下支持 UEFI 引导的，但因激活手段太差(传统引导的 OEM7F7 工具实在是太猛了)，并没有人想用 而且，UEFI 的 win7 也没什么优势，毕竟那会固态还不普及，开机速度更多还是硬盘限制 win7 过于成功，现在还存在 win7天下第一的神教，我都怀疑这波人就是当年吹 xp强于win7的那一群 就因为win7这帮人，到了win8的时代，也就出现了很多麻烦的事情 比如，自认为有两把刷子的小白给win8重装，还想着老一套 Ghost 还原方案，结果发现无法开机，各种翻车。原因在于 win8 出厂都是 UEFI 引导，有些人查到了百度的二手资料，得知要调整为 Legacy boot，但 Bios 里那一项却不让调整，就说电脑垃圾，win8 垃圾。 经历坎坷，关掉了 Security boot，后，装上了 win7，然后发现芯片组驱动不起来，usb不好用，声卡没声音，毕竟win8 的驱动没法给 win7 用，而很多笔记本没提供 win7 驱动，几乎是死局 以前的 PC 有一个叫法，称为 IBM PC 兼容机，现在的 PC 规范由多个公司组织联合制定，硬件型号相同，驱动也有很大程度的通用性。所以这个混沌的年代成功倒退了回去，只要单独安装驱动，就可以让不提供 win7 驱动的 笔记本，安装 win7 操作系统。又不是不能用 装系统的本质这不算是个故事，算是个人理解。 装系统的本质？ 解压缩 将解压缩的结果，引导起来 Over. 等等，就这？ 没错，就这。 谈论引导，以及多系统共存我对于引导的研究，更多的在于传统引导 那个年代很纯真，启动盘的活动分区的引导扇区，就那么点容量，读取出来执行代码，来决定如何引导操作系统 UEFI 其实更简单粗暴，也更灵活了， 第一个 fat/fat32 分区 /EFI/BOOT/BOOTX64.efi (不区分大小写)(只是默认情况，实际可以根据主板内写入的引导项指向其他文件) .efi 文件就是个可执行的二进制，电脑按照这之中的代码来决定如何引导操作系统 GPT分区表，并不是必须的 传统引导扇区，就那么点容量，现在的 efi 文件，一两 mb 都是可以的 多系统共存，难点其实在于规划，只要让多条引导拉起不同的系统，也就实现了共存。规划要让多个系统的文件分离开，确切说是互相不要产生不可控的影响 当然，最乱的时候，我的电脑里同时躺着4个系统 win7, xp, ubuntu, mac ubuntu是干啥的？导出声卡 codec 和 dsdt，以前玩黑果的人都知道 传统引导的多系统共存，只需要多个主分区即可，当然因为MBR的限制，最多只有四个分区(所有逻辑分区算一个，但逻辑分区无法引导)也就是，单硬盘四个可设置活动分区的主分区，就是极限。当然，正常人谁会用到那么多","link":"/2021/01/windows-planning-and-install/"}],"tags":[{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"环境","slug":"环境","link":"/tags/%E7%8E%AF%E5%A2%83/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"meta","slug":"meta","link":"/tags/meta/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"caddy","slug":"caddy","link":"/tags/caddy/"},{"name":"Iot","slug":"Iot","link":"/tags/Iot/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"ide","slug":"ide","link":"/tags/ide/"},{"name":"tools","slug":"tools","link":"/tags/tools/"},{"name":"后端","slug":"后端","link":"/tags/%E5%90%8E%E7%AB%AF/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"Vue.js","slug":"Vue-js","link":"/tags/Vue-js/"},{"name":"Nuxt.js","slug":"Nuxt-js","link":"/tags/Nuxt-js/"},{"name":"SEO","slug":"SEO","link":"/tags/SEO/"},{"name":"SSR","slug":"SSR","link":"/tags/SSR/"}],"categories":[{"name":"运维","slug":"运维","link":"/categories/%E8%BF%90%E7%BB%B4/"},{"name":"后端","slug":"后端","link":"/categories/%E5%90%8E%E7%AB%AF/"},{"name":"环境","slug":"环境","link":"/categories/%E7%8E%AF%E5%A2%83/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Java","slug":"后端/Java","link":"/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Iot","slug":"Iot","link":"/categories/Iot/"},{"name":"Mac","slug":"Mac","link":"/categories/Mac/"},{"name":"日常","slug":"日常","link":"/categories/%E6%97%A5%E5%B8%B8/"}]}